{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oILcV2ZHv7cZ"
      },
      "source": [
        "**Mount Google Drive in Colab to access our model and dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBxgrj1LdQGK",
        "outputId": "9352e98c-1bdc-42ce-b5d9-6e1cbd577788"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8q1fBagzwD5z"
      },
      "source": [
        "# Install YOLO and Other Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bjFPKA8Id5N1",
        "outputId": "0b3b4534-966f-406b-8e51-87dfee4c5819"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics  # YOLO package\n",
        "#!pip install opencv-python-headless  # For image processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ln1FROWreDz7",
        "outputId": "7daaf6b7-7d42-4003-ac1b-9a45af1c0981"
      },
      "outputs": [],
      "source": [
        "%cd '/content/drive/MyDrive/40984-CN/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJql-wanzAim"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "%ls 'VLP/data.yaml'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Evx9uGKdgIJq",
        "outputId": "3a643674-e872-4cb5-9ce5-f027d54f1e6c"
      },
      "outputs": [],
      "source": [
        "# !unzip 'VLP.v2i.yolov11.zip' -d 'VLP'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "27jHFeVOd0il",
        "outputId": "5073c1ae-af06-4807-e8ac-8306032a4736"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolo11n.pt')  # Start with a base model\n",
        "model.train(\n",
        "    data='VLP/data.yaml',       # Path to data config file\n",
        "    epochs=50,                  # Adjust based on dataset size and performance\n",
        "    imgsz=640,                  # Image size, adjust if needed\n",
        "    batch=8,                    # Adjust depending on your hardware\n",
        "    name='license_plate_detector'   # Name for this training session\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoWrxU6ExHE5"
      },
      "source": [
        "# Load Your Trained Model for License Plate Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3pcXFrxvIA4"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load the model\n",
        "model_path = 'runs/detect/license_plate_detector/weights/best.pt'  # Adjust the path as needed\n",
        "model = YOLO(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPugkZFAxFND"
      },
      "source": [
        "# Test License Plate Detection on Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "id": "i8DoP7p7vR08",
        "outputId": "1fb9dca1-8354-4798-9759-5a958b2cf57b"
      },
      "outputs": [],
      "source": [
        "# Run detection on an example image\n",
        "image_path = 'VLP/test/images/1071b237587a698b_jpg.rf.a754fb9c539a59ac64139521007eab1d.jpg'  # Adjust as needed\n",
        "\n",
        "# Perform detection\n",
        "results = model.predict(image_path)\n",
        "\n",
        "# Display the image with bounding boxes\n",
        "annotated_image = results[0].plot()\n",
        "cv2_imshow(annotated_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yG1o-tCsxWwL"
      },
      "source": [
        "# Test License Plate Detection on a Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hrMnQpcBxXFR",
        "outputId": "f621691d-1d88-4771-f915-cbd3e66b8d55"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "import time\n",
        "\n",
        "# Load the model\n",
        "model_path = 'runs/detect/license_plate_detector2/weights/best.pt'  # Adjust to your model's path\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# Open the video file\n",
        "video_path = 'C0142.mp4'  # Adjust as needed\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Set target resolution (optional, to reduce processing load)\n",
        "target_width = 1280\n",
        "target_height = 768\n",
        "\n",
        "# Process each frame\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Optionally resize the frame for better processing performance\n",
        "    if frame.shape[1] != target_width or frame.shape[0] != target_height:\n",
        "        frame = cv2.resize(frame, (target_width, target_height))\n",
        "\n",
        "    # Start time for measuring FPS\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Run YOLO detection on the frame\n",
        "    results = model.predict(frame, imgsz=(target_width, target_height))\n",
        "\n",
        "    # Get the annotated frame with bounding boxes\n",
        "    annotated_frame = results[0].plot()\n",
        "\n",
        "    # Display the annotated frame\n",
        "    cv2.imshow('License Plate Detection', annotated_frame)\n",
        "\n",
        "    # Print FPS (frames per second) for performance monitoring\n",
        "    fps = 1.0 / (time.time() - start_time)\n",
        "    print(f\"FPS: {fps:.2f}\")\n",
        "\n",
        "    # Exit on pressing 'q'\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release the video capture and close windows\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import time\n",
        "import math\n",
        "import easyocr\n",
        "import csv\n",
        "from collections import defaultdict, Counter\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the YOLO model for detection\n",
        "model_path = 'yolo11n.pt'  # Replace with the path to your model\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# Initialize the EasyOCR reader\n",
        "reader = easyocr.Reader(['en'])  # Adjust language as needed (e.g., 'es' for Spanish)\n",
        "\n",
        "# Define class names and colors for display\n",
        "classNames = {\n",
        "    0: \"person\", \n",
        "    1: \"bicycle\", \n",
        "    2: \"car\", \n",
        "    3: \"motorbike\", \n",
        "    5: \"bus\"\n",
        "}\n",
        "class_colors = {\n",
        "    0: (255, 0, 0),\n",
        "    1: (0, 255, 0),\n",
        "    2: (0, 0, 255),\n",
        "    3: (255, 255, 0),\n",
        "    5: (0, 255, 255)\n",
        "}\n",
        "\n",
        "# Open the video file and set up output for processed video\n",
        "video_path = 'C0142.mp4'  # Replace with the path to your input video\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "output_video_path = 'output_video.mp4'  # Path to save the annotated output video\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "# Prepare CSV file for logging\n",
        "csv_file_path = 'detection_tracking_log.csv'\n",
        "with open(csv_file_path, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['frame', 'object_type', 'confidence', 'tracking_id', 'x1', 'y1', 'x2', 'y2', \n",
        "                     'license_plate_confidence', 'mx1', 'my1', 'mx2', 'my2', 'license_plate_text'])\n",
        "\n",
        "# Persistent total count of each class across all frames\n",
        "total_class_count = Counter()\n",
        "# Track unique IDs for each class to count only once\n",
        "seen_ids = defaultdict(set)\n",
        "\n",
        "def put_text(frame, text, position, color=(0, 255, 0), font_scale=0.6, thickness=2, bg_color=(0, 0, 0)):\n",
        "    \"\"\"Helper function to put text with background on the frame.\"\"\"\n",
        "    text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)[0]\n",
        "    text_x, text_y = position\n",
        "    box_coords = ((text_x, text_y - text_size[1] - 5), (text_x + text_size[0] + 5, text_y + 5))\n",
        "    cv2.rectangle(frame, box_coords[0], box_coords[1], bg_color, cv2.FILLED)\n",
        "    cv2.putText(frame, text, position, cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, thickness)\n",
        "\n",
        "frame_number = 0  # Initialize frame counter\n",
        "\n",
        "# Loop through each frame\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Start time for measuring FPS\n",
        "    start_time = time.time()\n",
        "    frame_number += 1\n",
        "\n",
        "    # Run YOLO detection and tracking\n",
        "    results = model.track(frame, persist=True, classes=[0, 1, 2, 3, 5])  # Update classes as per model setup\n",
        "    current_frame_count = Counter()\n",
        "\n",
        "    # Process each detected object in the frame\n",
        "    for result in results:\n",
        "        boxes = result.boxes\n",
        "\n",
        "        for box in boxes:\n",
        "            # Get bounding box coordinates, class, and ID\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "            cls = int(box.cls[0])\n",
        "            confidence = math.ceil((box.conf[0] * 100)) / 100\n",
        "\n",
        "            # Track ID and count only if new\n",
        "            if box.id is not None:\n",
        "                track_id = int(box.id[0].tolist())\n",
        "                if track_id not in seen_ids[cls]:\n",
        "                    seen_ids[cls].add(track_id)\n",
        "                    total_class_count[classNames[cls]] += 1\n",
        "\n",
        "                # Draw bounding box and label with ID\n",
        "                color = class_colors.get(cls, (0, 255, 0))\n",
        "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 3)\n",
        "                put_text(frame, f\"{classNames[cls]} {confidence}\", (x1, y1 - 10), color=color, bg_color=(0, 0, 0))\n",
        "                put_text(frame, f\"ID: {track_id}\", (x1, y2 + 20), color=color, bg_color=(0, 0, 0))\n",
        "\n",
        "                # License plate recognition (OCR) if detected object is a car\n",
        "                license_plate_text = \"\"\n",
        "                plate_confidence = None\n",
        "                mx1, my1, mx2, my2 = None, None, None, None  # Coordinates for license plate bounding box\n",
        "\n",
        "                if classNames[cls] == \"car\":  # Check if the detected object is a car\n",
        "                    plate_img = frame[y1:y2, x1:x2]  # Crop the license plate area\n",
        "                    plate_results = reader.readtext(plate_img, allowlist='0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
        "                    if plate_results:\n",
        "                        license_plate_text = plate_results[0][-2]\n",
        "                        plate_confidence = round(plate_results[0][-1], 2)\n",
        "                        mx1, my1, mx2, my2 = x1, y1, x2, y2  # Save coordinates for CSV\n",
        "\n",
        "                        # Display license plate text on frame\n",
        "                        put_text(frame, f\"Plate: {license_plate_text}\", (x1, y2 + 40), color=(0, 255, 255), bg_color=(0, 0, 0))\n",
        "\n",
        "                # Write detection details to CSV\n",
        "                with open(csv_file_path, mode='a', newline='') as file:\n",
        "                    writer = csv.writer(file)\n",
        "                    writer.writerow([frame_number, classNames[cls], confidence, track_id, x1, y1, x2, y2, \n",
        "                                     plate_confidence, mx1, my1, mx2, my2, license_plate_text])\n",
        "\n",
        "                # Update current frame count\n",
        "                current_frame_count[classNames[cls]] += 1\n",
        "\n",
        "    # Display the total counts for each class on the frame\n",
        "    y_offset = 30\n",
        "    for cls, count in total_class_count.items():\n",
        "        put_text(frame, f\"Total {cls}: {count}\", (10, y_offset), color=(0, 255, 0), bg_color=(0, 0, 0))\n",
        "        y_offset += 20\n",
        "\n",
        "    # Display the current frame counts for each class on the frame\n",
        "    for cls, count in current_frame_count.items():\n",
        "        put_text(frame, f\"Frame {cls}: {count}\", (10, y_offset), color=(255, 0, 0), bg_color=(0, 0, 0))\n",
        "        y_offset += 20\n",
        "\n",
        "    # Calculate and display FPS\n",
        "    fps = 1.0 / (time.time() - start_time)\n",
        "    put_text(frame, f\"FPS: {fps:.2f}\", (10, y_offset), color=(255, 0, 0), bg_color=(0, 0, 0))\n",
        "\n",
        "    # Write frame to output video\n",
        "    out.write(frame)\n",
        "\n",
        "    # Show the frame\n",
        "    cv2.imshow('Detection and Tracking', frame)\n",
        "\n",
        "    # Exit on pressing 'q'\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release resources\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "VC_P1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
