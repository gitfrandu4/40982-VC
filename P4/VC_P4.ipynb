{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  \n",
    "import math \n",
    "\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelos preentrenados, visualizando con las utilidades de ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "WARNING ⚠️ inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "video 1/1 (frame 1/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 53.9ms\n",
      "video 1/1 (frame 2/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 32.1ms\n",
      "video 1/1 (frame 3/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 30.6ms\n",
      "video 1/1 (frame 4/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 36.9ms\n",
      "video 1/1 (frame 5/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 30.6ms\n",
      "video 1/1 (frame 6/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 27.5ms\n",
      "video 1/1 (frame 7/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 29.7ms\n",
      "video 1/1 (frame 8/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.3ms\n",
      "video 1/1 (frame 9/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 35.9ms\n",
      "video 1/1 (frame 10/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 26.7ms\n",
      "video 1/1 (frame 11/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 30.4ms\n",
      "video 1/1 (frame 12/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.9ms\n",
      "video 1/1 (frame 13/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 57.7ms\n",
      "video 1/1 (frame 14/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 34.0ms\n",
      "video 1/1 (frame 15/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 32.9ms\n",
      "video 1/1 (frame 16/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 26.8ms\n",
      "video 1/1 (frame 17/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 27.0ms\n",
      "video 1/1 (frame 18/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 55.3ms\n",
      "video 1/1 (frame 19/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 36.2ms\n",
      "video 1/1 (frame 20/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 41.1ms\n",
      "video 1/1 (frame 21/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 59.0ms\n",
      "video 1/1 (frame 22/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 39.0ms\n",
      "video 1/1 (frame 23/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 39.7ms\n",
      "video 1/1 (frame 24/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 34.0ms\n",
      "video 1/1 (frame 25/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 58.7ms\n",
      "video 1/1 (frame 26/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 31.4ms\n",
      "video 1/1 (frame 27/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 29.0ms\n",
      "video 1/1 (frame 28/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 34.4ms\n",
      "video 1/1 (frame 29/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 39.4ms\n",
      "video 1/1 (frame 30/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 40.4ms\n",
      "video 1/1 (frame 31/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 31.5ms\n",
      "video 1/1 (frame 32/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 38.1ms\n",
      "video 1/1 (frame 33/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 41.5ms\n",
      "video 1/1 (frame 34/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 39.3ms\n",
      "video 1/1 (frame 35/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 46.4ms\n",
      "video 1/1 (frame 36/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 33.0ms\n",
      "video 1/1 (frame 37/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 35.2ms\n",
      "video 1/1 (frame 38/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 52.1ms\n",
      "video 1/1 (frame 39/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 38.3ms\n",
      "video 1/1 (frame 40/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 32.0ms\n",
      "video 1/1 (frame 41/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 30.2ms\n",
      "video 1/1 (frame 42/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.8ms\n",
      "video 1/1 (frame 43/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 28.5ms\n",
      "video 1/1 (frame 44/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 29.9ms\n",
      "video 1/1 (frame 45/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 39.7ms\n",
      "video 1/1 (frame 46/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 39.4ms\n",
      "video 1/1 (frame 47/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 34.1ms\n",
      "video 1/1 (frame 48/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 37.3ms\n",
      "video 1/1 (frame 49/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 38.1ms\n",
      "video 1/1 (frame 50/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 36.6ms\n",
      "video 1/1 (frame 51/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 30.3ms\n",
      "video 1/1 (frame 52/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.8ms\n",
      "video 1/1 (frame 53/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 28.5ms\n",
      "video 1/1 (frame 54/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 34.2ms\n",
      "video 1/1 (frame 55/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 36.4ms\n",
      "video 1/1 (frame 56/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 48.6ms\n",
      "video 1/1 (frame 57/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 27.9ms\n",
      "video 1/1 (frame 58/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 26.2ms\n",
      "video 1/1 (frame 59/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 30.6ms\n",
      "video 1/1 (frame 60/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.2ms\n",
      "video 1/1 (frame 61/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 28.4ms\n",
      "video 1/1 (frame 62/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 24.6ms\n",
      "video 1/1 (frame 63/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.5ms\n",
      "video 1/1 (frame 64/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 27.4ms\n",
      "video 1/1 (frame 65/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 55.6ms\n",
      "video 1/1 (frame 66/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 27.7ms\n",
      "video 1/1 (frame 67/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.4ms\n",
      "video 1/1 (frame 68/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 24.4ms\n",
      "video 1/1 (frame 69/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.0ms\n",
      "video 1/1 (frame 70/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.4ms\n",
      "video 1/1 (frame 71/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 38.1ms\n",
      "video 1/1 (frame 72/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 26.8ms\n",
      "video 1/1 (frame 73/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.5ms\n",
      "video 1/1 (frame 74/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.4ms\n",
      "video 1/1 (frame 75/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 29.2ms\n",
      "video 1/1 (frame 76/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 34.9ms\n",
      "video 1/1 (frame 77/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 35.0ms\n",
      "video 1/1 (frame 78/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 37.5ms\n",
      "video 1/1 (frame 79/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 29.6ms\n",
      "video 1/1 (frame 80/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 29.8ms\n",
      "video 1/1 (frame 81/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 28.1ms\n",
      "video 1/1 (frame 82/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 27.2ms\n",
      "video 1/1 (frame 83/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 24.6ms\n",
      "video 1/1 (frame 84/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 28.8ms\n",
      "video 1/1 (frame 85/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 26.0ms\n",
      "video 1/1 (frame 86/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 26.3ms\n",
      "video 1/1 (frame 87/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 36.5ms\n",
      "video 1/1 (frame 88/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 27.6ms\n",
      "video 1/1 (frame 89/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 28.2ms\n",
      "video 1/1 (frame 90/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 26.2ms\n",
      "video 1/1 (frame 91/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 28.5ms\n",
      "video 1/1 (frame 92/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 27.4ms\n",
      "video 1/1 (frame 93/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.7ms\n",
      "video 1/1 (frame 94/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.1ms\n",
      "video 1/1 (frame 95/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 27.3ms\n",
      "video 1/1 (frame 96/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 26.7ms\n",
      "video 1/1 (frame 97/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 35.5ms\n",
      "video 1/1 (frame 98/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 42.3ms\n",
      "video 1/1 (frame 99/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 41.0ms\n",
      "video 1/1 (frame 100/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 40.1ms\n",
      "video 1/1 (frame 101/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 34.5ms\n",
      "video 1/1 (frame 102/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 30.3ms\n",
      "video 1/1 (frame 103/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.9ms\n",
      "video 1/1 (frame 104/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 28.0ms\n",
      "video 1/1 (frame 105/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 32.7ms\n",
      "video 1/1 (frame 106/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.0ms\n",
      "video 1/1 (frame 107/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 30.8ms\n",
      "video 1/1 (frame 108/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 24.9ms\n",
      "video 1/1 (frame 109/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 27.1ms\n",
      "video 1/1 (frame 110/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.0ms\n",
      "video 1/1 (frame 111/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 54.4ms\n",
      "video 1/1 (frame 112/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 29.6ms\n",
      "video 1/1 (frame 113/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 29.9ms\n",
      "video 1/1 (frame 114/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 40.3ms\n",
      "video 1/1 (frame 115/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 32.4ms\n",
      "video 1/1 (frame 116/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 26.7ms\n",
      "video 1/1 (frame 117/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 29.2ms\n",
      "video 1/1 (frame 118/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.7ms\n",
      "video 1/1 (frame 119/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 24.9ms\n",
      "video 1/1 (frame 120/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 28.9ms\n",
      "video 1/1 (frame 121/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 30.2ms\n",
      "video 1/1 (frame 122/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 28.4ms\n",
      "video 1/1 (frame 123/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 29.6ms\n",
      "video 1/1 (frame 124/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 29.5ms\n",
      "video 1/1 (frame 125/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 26.9ms\n",
      "video 1/1 (frame 126/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 28.9ms\n",
      "video 1/1 (frame 127/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 32.4ms\n",
      "video 1/1 (frame 128/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 28.1ms\n",
      "video 1/1 (frame 129/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.6ms\n",
      "video 1/1 (frame 130/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 43.3ms\n",
      "video 1/1 (frame 131/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 41.5ms\n",
      "video 1/1 (frame 132/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 32.6ms\n",
      "video 1/1 (frame 133/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 29.2ms\n",
      "video 1/1 (frame 134/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 27.4ms\n",
      "video 1/1 (frame 135/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 29.6ms\n",
      "video 1/1 (frame 136/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 34.5ms\n",
      "video 1/1 (frame 137/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 28.1ms\n",
      "video 1/1 (frame 138/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.3ms\n",
      "video 1/1 (frame 139/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.0ms\n",
      "video 1/1 (frame 140/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 26.6ms\n",
      "video 1/1 (frame 141/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 44.8ms\n",
      "video 1/1 (frame 142/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 35.6ms\n",
      "video 1/1 (frame 143/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 28.7ms\n",
      "video 1/1 (frame 144/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 26.9ms\n",
      "video 1/1 (frame 145/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 27.5ms\n",
      "video 1/1 (frame 146/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 26.1ms\n",
      "video 1/1 (frame 147/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.4ms\n",
      "video 1/1 (frame 148/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 27.4ms\n",
      "video 1/1 (frame 149/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.4ms\n",
      "video 1/1 (frame 150/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.7ms\n",
      "video 1/1 (frame 151/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 24.8ms\n",
      "video 1/1 (frame 152/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 27.0ms\n",
      "video 1/1 (frame 153/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 24.9ms\n",
      "video 1/1 (frame 154/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 35.4ms\n",
      "video 1/1 (frame 155/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 32.9ms\n",
      "video 1/1 (frame 156/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.3ms\n",
      "video 1/1 (frame 157/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.6ms\n",
      "video 1/1 (frame 158/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 26.1ms\n",
      "video 1/1 (frame 159/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 29.8ms\n",
      "video 1/1 (frame 160/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 31.7ms\n",
      "video 1/1 (frame 161/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 33.6ms\n",
      "video 1/1 (frame 162/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 28.6ms\n",
      "video 1/1 (frame 163/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 36.9ms\n",
      "video 1/1 (frame 164/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.7ms\n",
      "video 1/1 (frame 165/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 29.6ms\n",
      "video 1/1 (frame 166/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 24.8ms\n",
      "video 1/1 (frame 167/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.0ms\n",
      "video 1/1 (frame 168/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.1ms\n",
      "video 1/1 (frame 169/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 27.0ms\n",
      "video 1/1 (frame 170/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 28.7ms\n",
      "video 1/1 (frame 171/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.6ms\n",
      "video 1/1 (frame 172/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 26.4ms\n",
      "video 1/1 (frame 173/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 26.4ms\n",
      "video 1/1 (frame 174/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 32.9ms\n",
      "video 1/1 (frame 175/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 27.0ms\n",
      "video 1/1 (frame 176/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 34.5ms\n",
      "video 1/1 (frame 177/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.7ms\n",
      "video 1/1 (frame 178/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 24.4ms\n",
      "video 1/1 (frame 179/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 27.1ms\n",
      "video 1/1 (frame 180/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 28.0ms\n",
      "video 1/1 (frame 181/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.9ms\n",
      "video 1/1 (frame 182/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 27.6ms\n",
      "video 1/1 (frame 183/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 26.4ms\n",
      "video 1/1 (frame 184/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 26.3ms\n",
      "video 1/1 (frame 185/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 45.5ms\n",
      "video 1/1 (frame 186/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 59.4ms\n",
      "video 1/1 (frame 187/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 36.5ms\n",
      "video 1/1 (frame 188/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 29.9ms\n",
      "video 1/1 (frame 189/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 30.1ms\n",
      "video 1/1 (frame 190/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 31.7ms\n",
      "video 1/1 (frame 191/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 27.3ms\n",
      "video 1/1 (frame 192/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 27.5ms\n",
      "video 1/1 (frame 193/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.5ms\n",
      "video 1/1 (frame 194/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 27.8ms\n",
      "video 1/1 (frame 195/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 27.8ms\n",
      "video 1/1 (frame 196/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 26.2ms\n",
      "video 1/1 (frame 197/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 28.2ms\n",
      "video 1/1 (frame 198/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.3ms\n",
      "video 1/1 (frame 199/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 30.9ms\n",
      "video 1/1 (frame 200/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 27.7ms\n",
      "video 1/1 (frame 201/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 48.3ms\n",
      "video 1/1 (frame 202/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 27.2ms\n",
      "video 1/1 (frame 203/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 27.0ms\n",
      "video 1/1 (frame 204/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 24.7ms\n",
      "video 1/1 (frame 205/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 33.1ms\n",
      "video 1/1 (frame 206/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 26.4ms\n",
      "video 1/1 (frame 207/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 24.2ms\n",
      "video 1/1 (frame 208/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 26.4ms\n",
      "video 1/1 (frame 209/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 24.9ms\n",
      "video 1/1 (frame 210/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 24.8ms\n",
      "video 1/1 (frame 211/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 24.7ms\n",
      "video 1/1 (frame 212/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 28.6ms\n",
      "video 1/1 (frame 213/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 25.0ms\n",
      "video 1/1 (frame 214/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 25.9ms\n",
      "video 1/1 (frame 215/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 28.7ms\n",
      "video 1/1 (frame 216/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 27.5ms\n",
      "video 1/1 (frame 217/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 27.4ms\n",
      "video 1/1 (frame 218/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 25.6ms\n",
      "video 1/1 (frame 219/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 42.1ms\n",
      "video 1/1 (frame 220/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 25.9ms\n",
      "video 1/1 (frame 221/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 27.3ms\n",
      "video 1/1 (frame 222/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 26.4ms\n",
      "video 1/1 (frame 223/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 26.7ms\n",
      "video 1/1 (frame 224/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 25.5ms\n",
      "video 1/1 (frame 225/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 25.2ms\n",
      "video 1/1 (frame 226/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 34.4ms\n",
      "video 1/1 (frame 227/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 25.1ms\n",
      "video 1/1 (frame 228/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 43.2ms\n",
      "video 1/1 (frame 229/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 29.4ms\n",
      "video 1/1 (frame 230/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 35.4ms\n",
      "video 1/1 (frame 231/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 29.7ms\n",
      "video 1/1 (frame 232/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 27.3ms\n",
      "video 1/1 (frame 233/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 25.3ms\n",
      "video 1/1 (frame 234/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 26.2ms\n",
      "video 1/1 (frame 235/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 25.8ms\n",
      "video 1/1 (frame 236/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 40.1ms\n",
      "video 1/1 (frame 237/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 25.6ms\n",
      "video 1/1 (frame 238/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 27.2ms\n",
      "video 1/1 (frame 239/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 25.1ms\n",
      "video 1/1 (frame 240/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 25.0ms\n",
      "video 1/1 (frame 241/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 25.1ms\n",
      "video 1/1 (frame 242/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 24.9ms\n",
      "video 1/1 (frame 243/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 25.1ms\n",
      "video 1/1 (frame 244/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 25.3ms\n",
      "video 1/1 (frame 245/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 39.1ms\n",
      "video 1/1 (frame 246/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 25.5ms\n",
      "video 1/1 (frame 247/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 26.1ms\n",
      "video 1/1 (frame 248/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 24.6ms\n",
      "video 1/1 (frame 249/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 25.1ms\n",
      "video 1/1 (frame 250/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 27.7ms\n",
      "video 1/1 (frame 251/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 27.5ms\n",
      "video 1/1 (frame 252/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 29.1ms\n",
      "video 1/1 (frame 253/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 26.6ms\n",
      "video 1/1 (frame 254/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 24.7ms\n",
      "video 1/1 (frame 255/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 25.6ms\n",
      "video 1/1 (frame 256/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 28.2ms\n",
      "video 1/1 (frame 257/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 67.8ms\n",
      "video 1/1 (frame 258/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 34.1ms\n",
      "video 1/1 (frame 259/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 40.1ms\n",
      "video 1/1 (frame 260/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 37.1ms\n",
      "video 1/1 (frame 261/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 37.0ms\n",
      "video 1/1 (frame 262/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 33.0ms\n",
      "video 1/1 (frame 263/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 39.3ms\n",
      "video 1/1 (frame 264/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 43.2ms\n",
      "video 1/1 (frame 265/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 46.4ms\n",
      "video 1/1 (frame 266/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 28.6ms\n",
      "video 1/1 (frame 267/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 46.0ms\n",
      "video 1/1 (frame 268/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 39.3ms\n",
      "video 1/1 (frame 269/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 25.5ms\n",
      "video 1/1 (frame 270/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 29.0ms\n",
      "video 1/1 (frame 271/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 24.7ms\n",
      "video 1/1 (frame 272/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 24.1ms\n",
      "video 1/1 (frame 273/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 26.9ms\n",
      "video 1/1 (frame 274/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 29.5ms\n",
      "video 1/1 (frame 275/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 45.5ms\n",
      "video 1/1 (frame 276/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 37.4ms\n",
      "video 1/1 (frame 277/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 37.3ms\n",
      "video 1/1 (frame 278/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 43.8ms\n",
      "video 1/1 (frame 279/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 33.6ms\n",
      "video 1/1 (frame 280/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 32.0ms\n",
      "video 1/1 (frame 281/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 33.1ms\n",
      "video 1/1 (frame 282/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 32.8ms\n",
      "video 1/1 (frame 283/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 43.3ms\n",
      "video 1/1 (frame 284/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 36.6ms\n",
      "video 1/1 (frame 285/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 2 persons, 49.5ms\n",
      "video 1/1 (frame 286/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 49.5ms\n",
      "video 1/1 (frame 287/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 42.1ms\n",
      "video 1/1 (frame 288/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 59.7ms\n",
      "video 1/1 (frame 289/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 40.9ms\n",
      "video 1/1 (frame 290/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 27.4ms\n",
      "video 1/1 (frame 291/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 33.1ms\n",
      "video 1/1 (frame 292/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 24.5ms\n",
      "video 1/1 (frame 293/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 26.0ms\n",
      "video 1/1 (frame 294/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 25.3ms\n",
      "video 1/1 (frame 295/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 25.6ms\n",
      "video 1/1 (frame 296/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 31.7ms\n",
      "video 1/1 (frame 297/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 27.3ms\n",
      "video 1/1 (frame 298/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 25.0ms\n",
      "video 1/1 (frame 299/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 24.9ms\n",
      "video 1/1 (frame 300/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 26.7ms\n",
      "video 1/1 (frame 301/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 31.3ms\n",
      "video 1/1 (frame 302/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 29.2ms\n",
      "video 1/1 (frame 303/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 25.4ms\n",
      "video 1/1 (frame 304/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 30.6ms\n",
      "video 1/1 (frame 305/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 36.0ms\n",
      "video 1/1 (frame 306/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 37.4ms\n",
      "video 1/1 (frame 307/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 29.5ms\n",
      "video 1/1 (frame 308/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 27.2ms\n",
      "video 1/1 (frame 309/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 27.1ms\n",
      "video 1/1 (frame 310/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 32.0ms\n",
      "video 1/1 (frame 311/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 25.9ms\n",
      "video 1/1 (frame 312/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 34.7ms\n",
      "video 1/1 (frame 313/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 25.8ms\n",
      "video 1/1 (frame 314/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 30.7ms\n",
      "video 1/1 (frame 315/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 26.1ms\n",
      "video 1/1 (frame 316/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 1 person, 28.3ms\n",
      "video 1/1 (frame 317/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 24.3ms\n",
      "video 1/1 (frame 318/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 26.7ms\n",
      "video 1/1 (frame 319/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 24.4ms\n",
      "video 1/1 (frame 320/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 26.0ms\n",
      "video 1/1 (frame 321/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 24.8ms\n",
      "video 1/1 (frame 322/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.3ms\n",
      "video 1/1 (frame 323/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 27.9ms\n",
      "video 1/1 (frame 324/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 33.0ms\n",
      "video 1/1 (frame 325/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 28.3ms\n",
      "video 1/1 (frame 326/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 26.2ms\n",
      "video 1/1 (frame 327/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 26.8ms\n",
      "video 1/1 (frame 328/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 26.7ms\n",
      "video 1/1 (frame 329/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.5ms\n",
      "video 1/1 (frame 330/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 27.0ms\n",
      "video 1/1 (frame 331/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.5ms\n",
      "video 1/1 (frame 332/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 24.1ms\n",
      "video 1/1 (frame 333/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.5ms\n",
      "video 1/1 (frame 334/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 26.2ms\n",
      "video 1/1 (frame 335/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 24.8ms\n",
      "video 1/1 (frame 336/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 27.3ms\n",
      "video 1/1 (frame 337/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.2ms\n",
      "video 1/1 (frame 338/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.9ms\n",
      "video 1/1 (frame 339/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 26.8ms\n",
      "video 1/1 (frame 340/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 28.3ms\n",
      "video 1/1 (frame 341/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 27.5ms\n",
      "video 1/1 (frame 342/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 26.3ms\n",
      "video 1/1 (frame 343/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 28.2ms\n",
      "video 1/1 (frame 344/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 26.4ms\n",
      "video 1/1 (frame 345/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.8ms\n",
      "video 1/1 (frame 346/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.3ms\n",
      "video 1/1 (frame 347/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.5ms\n",
      "video 1/1 (frame 348/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 29.3ms\n",
      "video 1/1 (frame 349/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.3ms\n",
      "video 1/1 (frame 350/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 47.5ms\n",
      "video 1/1 (frame 351/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 33.4ms\n",
      "video 1/1 (frame 352/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 28.9ms\n",
      "video 1/1 (frame 353/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.5ms\n",
      "video 1/1 (frame 354/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 29.7ms\n",
      "video 1/1 (frame 355/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.6ms\n",
      "video 1/1 (frame 356/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 26.3ms\n",
      "video 1/1 (frame 357/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.6ms\n",
      "video 1/1 (frame 358/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 28.6ms\n",
      "video 1/1 (frame 359/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 24.8ms\n",
      "video 1/1 (frame 360/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 24.3ms\n",
      "video 1/1 (frame 361/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.9ms\n",
      "video 1/1 (frame 362/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 43.2ms\n",
      "video 1/1 (frame 363/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.0ms\n",
      "video 1/1 (frame 364/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.9ms\n",
      "video 1/1 (frame 365/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 26.2ms\n",
      "video 1/1 (frame 366/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 29.2ms\n",
      "video 1/1 (frame 367/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 26.4ms\n",
      "video 1/1 (frame 368/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 24.8ms\n",
      "video 1/1 (frame 369/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 26.3ms\n",
      "video 1/1 (frame 370/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 56.7ms\n",
      "video 1/1 (frame 371/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 25.6ms\n",
      "video 1/1 (frame 372/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 28.5ms\n",
      "video 1/1 (frame 373/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 26.2ms\n",
      "video 1/1 (frame 374/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 26.3ms\n",
      "video 1/1 (frame 375/375) /Users/franciscoj./Documents/GII-41/40982-VC/P4/TGC23_PdH_C0056cut.mp4: 384x640 (no detections), 26.5ms\n",
      "Speed: 1.2ms preprocess, 30.8ms inference, 0.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "# Carga del modelo\n",
    "#model = YOLO('yolo11n.pt') #Contenedores\n",
    "#model = YOLO('yolo11n-seg.pt') #Máscaras\n",
    "model = YOLO('yolo11n-pose.pt')  #Pose\n",
    "\n",
    "#Para un vídeo \n",
    "filename = \"TGC23_PdH_C0056cut.mp4\"\n",
    "results = model(filename, show=True)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desde cámara, detección con yolo11, modelo nano. Visualización propia con OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 45.5ms\n",
      "Speed: 2.2ms preprocess, 45.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 chairs, 53.2ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> chair\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> chair\n",
      "Speed: 2.1ms preprocess, 53.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 chair, 44.2ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> chair\n",
      "Speed: 2.0ms preprocess, 44.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 44.0ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 44.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 154.2ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "Speed: 7.3ms preprocess, 154.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 48.5ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 48.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 83.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 83.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 61.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 5.1ms preprocess, 61.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 55.8ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 55.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 57.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 57.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 43.5ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 46.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 2.4ms preprocess, 46.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 45.3ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 45.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 40.6ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 40.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 41.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 41.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 80.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 4.5ms preprocess, 80.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 30.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.59\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 30.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 77.7ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 16.8ms preprocess, 77.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 42.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 42.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 41.8ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 41.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 66.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 66.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 37.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "Speed: 2.6ms preprocess, 37.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 41.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Speed: 3.8ms preprocess, 41.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 37.8ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 37.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 30.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 30.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 38.5ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 5.5ms preprocess, 38.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 36.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 36.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 40.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Speed: 5.6ms preprocess, 40.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 37.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 37.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 33.9ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 33.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 52.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 52.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 40.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 40.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 32.6ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Speed: 2.2ms preprocess, 32.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 32.7ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 32.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 37.8ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 37.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 40.0ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 40.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.5ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 36.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.7ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 34.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 40.6ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 40.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 32.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 32.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 30.3ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 30.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.1ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 34.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 30.6ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 30.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.5ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 37.5ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 31.8ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 31.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.4ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 37.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 31.8ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 31.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 30.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 30.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.6ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 5.1ms preprocess, 34.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 33.2ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> tie\n",
      "Speed: 1.5ms preprocess, 33.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.3ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 37.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 32.8ms\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 32.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 28.9ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.64\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 28.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 35.4ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 35.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 42.5ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 42.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 37.8ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 37.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 39.3ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 39.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 36.2ms\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "Confianza ---> 0.81\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "Speed: 4.6ms preprocess, 36.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 36.0ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 4.0ms preprocess, 36.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 38.0ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 38.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 40.7ms\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "Confianza ---> 0.77\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 40.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 48.3ms\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "Confianza ---> 0.83\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 48.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 51.0ms\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "Confianza ---> 0.73\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 2.2ms preprocess, 51.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 33.5ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 33.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 35.7ms\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "Confianza ---> 0.71\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 35.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 42.7ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 42.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 32.2ms\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> cell phone\n",
      "Speed: 2.2ms preprocess, 32.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 41.1ms\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "Confianza ---> 0.73\n",
      "Clase --> cell phone\n",
      "Speed: 1.9ms preprocess, 41.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 32.2ms\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> cell phone\n",
      "Speed: 1.5ms preprocess, 32.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 34.6ms\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> cell phone\n",
      "Speed: 1.5ms preprocess, 34.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 36.6ms\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "Confianza ---> 0.68\n",
      "Clase --> cell phone\n",
      "Speed: 1.5ms preprocess, 36.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 33.4ms\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "Confianza ---> 0.75\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 33.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 35.9ms\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "Confianza ---> 0.73\n",
      "Clase --> cell phone\n",
      "Speed: 1.6ms preprocess, 35.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 cell phone, 35.6ms\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "Confianza ---> 0.75\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 35.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 37.0ms\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "Confianza ---> 0.78\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 37.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 35.2ms\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "Confianza ---> 0.79\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 35.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 36.7ms\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "Confianza ---> 0.69\n",
      "Clase --> cell phone\n",
      "Speed: 1.5ms preprocess, 36.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 34.6ms\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "Confianza ---> 0.61\n",
      "Clase --> cell phone\n",
      "Speed: 1.8ms preprocess, 34.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 32.6ms\n",
      "Confianza ---> 0.81\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.79\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 32.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 cell phones, 33.9ms\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "Confianza ---> 0.68\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.44\n",
      "Clase --> cell phone\n",
      "Speed: 1.6ms preprocess, 33.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 32.3ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 32.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 36.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 56.9ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 2.3ms preprocess, 56.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 53.6ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Speed: 2.8ms preprocess, 53.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 43.2ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 43.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 45.7ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 45.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 39.4ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 39.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 39.2ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.6\n",
      "Clase --> person\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 39.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 38.9ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 38.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 32.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 32.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 32.7ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 32.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 33.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 33.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 30.5ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 30.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 29.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 29.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 35.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 2.8ms preprocess, 35.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 34.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 34.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 37.9ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 37.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 65.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 65.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "Speed: 2.4ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 35.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 33.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 33.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.6ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 35.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 55.0ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "Speed: 2.9ms preprocess, 55.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.1ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 35.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.0ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 35.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.9ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 33.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 32.6ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 32.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 30.7ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.8\n",
      "Clase --> cell phone\n",
      "Speed: 1.9ms preprocess, 30.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 31.8ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.57\n",
      "Clase --> cell phone\n",
      "Speed: 1.5ms preprocess, 31.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.9ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Speed: 2.4ms preprocess, 34.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 87.1ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 87.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 46.0ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 46.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 45.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 45.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 45.0ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> cell phone\n",
      "Speed: 3.2ms preprocess, 45.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 31.7ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 31.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 28.7ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> cell phone\n",
      "Speed: 1.6ms preprocess, 28.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 38.2ms\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "Confianza ---> 0.62\n",
      "Clase --> cell phone\n",
      "Speed: 1.7ms preprocess, 38.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 cell phones, 31.7ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.77\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> cell phone\n",
      "Speed: 3.2ms preprocess, 31.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 38.5ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "Confianza ---> 0.68\n",
      "Clase --> cell phone\n",
      "Speed: 1.8ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 37.5ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> cell phone\n",
      "Speed: 1.8ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 58.5ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "Confianza ---> 0.75\n",
      "Clase --> cell phone\n",
      "Speed: 1.6ms preprocess, 58.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 40.1ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "Confianza ---> 0.6\n",
      "Clase --> cell phone\n",
      "Speed: 1.4ms preprocess, 40.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 40.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "Confianza ---> 0.58\n",
      "Clase --> cell phone\n",
      "Speed: 1.7ms preprocess, 40.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 37.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "Confianza ---> 0.73\n",
      "Clase --> cell phone\n",
      "Speed: 1.4ms preprocess, 37.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 33.6ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "Confianza ---> 0.57\n",
      "Clase --> cell phone\n",
      "Speed: 1.5ms preprocess, 33.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 35.7ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "Confianza ---> 0.71\n",
      "Clase --> cell phone\n",
      "Speed: 1.6ms preprocess, 35.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 wine glass, 2 cell phones, 31.8ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.35\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.26\n",
      "Clase --> wine glass\n",
      "Speed: 1.7ms preprocess, 31.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 36.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "Confianza ---> 0.64\n",
      "Clase --> cell phone\n",
      "Speed: 1.6ms preprocess, 36.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 30.7ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> cell phone\n",
      "Speed: 1.6ms preprocess, 30.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 39.0ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> cell phone\n",
      "Speed: 1.7ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 36.0ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> cell phone\n",
      "Speed: 2.0ms preprocess, 36.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 45.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 45.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 42.0ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 42.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 34.4ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 34.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 36.2ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> cell phone\n",
      "Speed: 1.5ms preprocess, 36.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 34.9ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> cell phone\n",
      "Speed: 1.9ms preprocess, 34.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 37.3ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 37.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.5ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 36.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 32.4ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 32.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.5ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 35.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 39.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 39.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 33.1ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 33.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 44.7ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "Speed: 4.0ms preprocess, 44.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 32.9ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Speed: 2.3ms preprocess, 32.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 30.3ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "Confianza ---> 0.54\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 30.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 38.8ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Speed: 2.8ms preprocess, 38.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 47.4ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.6\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 47.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 33.4ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 33.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 29.8ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 29.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 33.3ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 33.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 31.9ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 31.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.8ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 35.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 32.7ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 32.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 36.4ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 36.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 31.7ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 31.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 36.4ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.59\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 36.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 31.2ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 31.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 41.7ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 41.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 30.9ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 3.5ms preprocess, 30.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.7ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 8.5ms preprocess, 38.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 33.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Speed: 2.6ms preprocess, 33.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.6ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 33.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 32.5ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 5.1ms preprocess, 32.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 43.5ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 43.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.7ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 37.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 40.6ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 40.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 66.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 66.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 41.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 3.4ms preprocess, 41.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 48.8ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 48.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 47.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 47.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 41.2ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 41.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 39.7ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 39.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 48.7ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.56\n",
      "Clase --> person\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 48.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 49.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "Confianza ---> 0.58\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 49.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 47.3ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 47.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 41.2ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 41.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 37.4ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "Confianza ---> 0.56\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 37.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 32.5ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 32.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 37.1ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 37.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.6ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 36.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 46.8ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "Confianza ---> 0.46\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 46.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 29.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 29.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 34.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 3.9ms preprocess, 38.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 32.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 32.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 34.6ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 34.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 33.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 33.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 34.6ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 2.2ms preprocess, 34.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 54.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 2.2ms preprocess, 54.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.5ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 3.2ms preprocess, 35.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 39.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 36.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 29.8ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 29.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.7ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 36.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 34.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.3ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 33.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 31.6ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 31.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.8ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 2.2ms preprocess, 36.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 37.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 37.7ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 37.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 36.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.8ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 36.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 40.5ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 40.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 33.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 33.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.7ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 38.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 31.8ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 31.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 frisbee, 33.6ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> frisbee\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 33.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 30.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 30.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 38.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 48.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 48.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 43.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 43.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 35.9ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 3.4ms preprocess, 35.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 34.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 34.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 35.5ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 35.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 32.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 32.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.9ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 39.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 39.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 33.8ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 33.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 32.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 32.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 29.5ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 29.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.9ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 34.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 33.6ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 33.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.3ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 35.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 32.2ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 32.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 31.5ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 31.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 scissors, 43.2ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> scissors\n",
      "Speed: 5.4ms preprocess, 43.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 1 scissors, 37.0ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> scissors\n",
      "Confianza ---> 0.26\n",
      "Clase --> cell phone\n",
      "Speed: 5.7ms preprocess, 37.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 34.2ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 34.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 28.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 28.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 33.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> cell phone\n",
      "Speed: 4.5ms preprocess, 33.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 36.2ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.62\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 36.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 35.1ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 3.7ms preprocess, 35.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 51.3ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.46\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 2.4ms preprocess, 51.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 33.6ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> cell phone\n",
      "Speed: 1.6ms preprocess, 33.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 36.6ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 36.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.0ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 36.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 35.2ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> cell phone\n",
      "Speed: 2.1ms preprocess, 35.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.8ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 3.7ms preprocess, 35.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 33.7ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 33.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 39.2ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 39.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.6ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 36.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 29.8ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 29.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.4ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 35.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 63.2ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 63.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 51.9ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 51.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 59.7ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 59.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 61.6ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Speed: 2.3ms preprocess, 61.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 78.9ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 78.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 38.8ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 38.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 47.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.46\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 47.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 38.6ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> cell phone\n",
      "Speed: 1.8ms preprocess, 38.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 36.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 38.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 60.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 2.7ms preprocess, 60.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 30.7ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 30.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.8ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 38.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 32.5ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 32.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 38.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 32.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 32.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 36.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.5ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 39.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 52.1ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 52.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 39.8ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 18.7ms preprocess, 39.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.6ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 6.3ms preprocess, 37.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.7ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 35.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 32.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 32.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 33.6ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 33.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 31.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 31.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 38.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 38.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.6ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 39.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 31.7ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 2.2ms preprocess, 31.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 36.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 32.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 4.6ms preprocess, 32.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 28.6ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 28.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 32.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 32.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 51.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 51.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 40.5ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 40.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.0ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 36.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.2ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 35.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 34.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 32.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 32.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.4ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 35.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.5ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 36.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 33.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.2ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 37.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.1ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 33.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.3ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 34.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 37.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 36.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 35.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.6ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 36.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.1ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 35.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.6ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 38.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.6ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 36.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 32.6ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 32.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 32.3ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 32.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 32.7ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 32.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.8ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 36.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.6ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 35.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.6ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 39.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 39.2ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 39.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 46.0ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 46.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.2ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 37.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 31.9ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 31.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.5ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 34.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.2ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 35.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.7ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 33.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.5ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 34.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 28.8ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 3.6ms preprocess, 28.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 34.9ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 34.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 32.3ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 32.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.2ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Speed: 2.2ms preprocess, 35.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 34.5ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.65\n",
      "Clase --> cell phone\n",
      "Speed: 2.1ms preprocess, 34.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 39.0ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.75\n",
      "Clase --> cell phone\n",
      "Speed: 2.6ms preprocess, 39.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 36.5ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> cell phone\n",
      "Speed: 2.1ms preprocess, 36.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 31.6ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.76\n",
      "Clase --> cell phone\n",
      "Speed: 1.4ms preprocess, 31.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 39.2ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> cell phone\n",
      "Speed: 1.7ms preprocess, 39.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 32.4ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.84\n",
      "Clase --> cell phone\n",
      "Speed: 1.4ms preprocess, 32.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 29.5ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.84\n",
      "Clase --> cell phone\n",
      "Speed: 1.8ms preprocess, 29.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 32.9ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.71\n",
      "Clase --> cell phone\n",
      "Speed: 3.4ms preprocess, 32.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 34.9ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.8\n",
      "Clase --> cell phone\n",
      "Speed: 2.0ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 38.6ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.8\n",
      "Clase --> cell phone\n",
      "Speed: 1.7ms preprocess, 38.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 54.8ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.87\n",
      "Clase --> cell phone\n",
      "Speed: 1.7ms preprocess, 54.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 39.0ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.74\n",
      "Clase --> cell phone\n",
      "Speed: 1.6ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 45.0ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.6\n",
      "Clase --> cell phone\n",
      "Speed: 1.7ms preprocess, 45.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 37.3ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.76\n",
      "Clase --> cell phone\n",
      "Speed: 1.7ms preprocess, 37.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 40.7ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.8\n",
      "Clase --> cell phone\n",
      "Speed: 3.7ms preprocess, 40.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 30.8ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.68\n",
      "Clase --> cell phone\n",
      "Speed: 5.9ms preprocess, 30.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 38.0ms\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "Confianza ---> 0.81\n",
      "Clase --> cell phone\n",
      "Speed: 1.6ms preprocess, 38.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 remote, 1 cell phone, 31.4ms\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.35\n",
      "Clase --> remote\n",
      "Speed: 2.0ms preprocess, 31.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 remote, 1 cell phone, 33.5ms\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.38\n",
      "Clase --> remote\n",
      "Speed: 1.4ms preprocess, 33.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 31.7ms\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "Confianza ---> 0.81\n",
      "Clase --> cell phone\n",
      "Speed: 1.6ms preprocess, 31.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 34.9ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.79\n",
      "Clase --> cell phone\n",
      "Speed: 3.8ms preprocess, 34.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 45.9ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 45.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 33.4ms\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "Confianza ---> 0.84\n",
      "Clase --> cell phone\n",
      "Speed: 5.1ms preprocess, 33.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 32.0ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.85\n",
      "Clase --> cell phone\n",
      "Speed: 12.5ms preprocess, 32.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 31.2ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.79\n",
      "Clase --> cell phone\n",
      "Speed: 1.7ms preprocess, 31.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 31.8ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.86\n",
      "Clase --> cell phone\n",
      "Speed: 4.6ms preprocess, 31.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 32.2ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 32.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 38.1ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 38.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 45.3ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.81\n",
      "Clase --> cell phone\n",
      "Speed: 1.7ms preprocess, 45.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 40.4ms\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "Confianza ---> 0.84\n",
      "Clase --> cell phone\n",
      "Speed: 1.5ms preprocess, 40.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 43.0ms\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 43.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 42.3ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 42.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 46.9ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 46.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 46.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 46.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 51.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 51.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 46.1ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 2.2ms preprocess, 46.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 40.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 40.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.5ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 36.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.9ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 34.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.6ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 33.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 30.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 30.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 38.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.7ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 33.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 41.4ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 41.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 40.2ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 40.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 34.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 31.8ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 31.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 37.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 35.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.5ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 34.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.0ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 36.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 30.8ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 30.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 32.9ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 32.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.3ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 33.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 53.5ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 53.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 38.8ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 38.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.8ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 33.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 45.1ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 45.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 35.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 37.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.6ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 38.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.8ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 37.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.1ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 36.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 30.3ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 30.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.7ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 34.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.6ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 36.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.9ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 33.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.6ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 36.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.2ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 35.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 52.7ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 5.6ms preprocess, 52.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.3ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 36.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 41.4ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 41.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.6ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 36.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 46.0ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 46.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 39.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 2.2ms preprocess, 33.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 30.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 30.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 53.9ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 53.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 31.8ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 31.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 42.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 42.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 41.0ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 2.4ms preprocess, 41.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.8ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 38.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.8ms\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 36.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.0ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 34.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 30.5ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 30.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.3ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 3.4ms preprocess, 33.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 32.0ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 32.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 32.8ms\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 32.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.0ms\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Speed: 4.0ms preprocess, 35.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.6ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 33.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 29.9ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 29.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 44.6ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 44.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 40.4ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 40.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 57.2ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 57.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 58.2ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 58.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 52.4ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 52.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 46.2ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 46.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 40.9ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 2.2ms preprocess, 40.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.3ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 33.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 50.9ms\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Speed: 4.5ms preprocess, 50.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.6ms\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 34.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.2ms\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Speed: 3.6ms preprocess, 34.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.9ms\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 33.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 40.6ms\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 40.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 31.2ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 31.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.9ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 34.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.1ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 33.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.1ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 33.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.8ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 36.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 32.5ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 32.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.2ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 8.8ms preprocess, 34.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.0ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 34.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 28.3ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 28.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 32.3ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 32.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.9ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 37.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 38.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 34.7ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 34.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 37.4ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 37.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.3ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 35.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.5ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 39.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 54.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Speed: 4.8ms preprocess, 54.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 68.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 5.0ms preprocess, 68.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 41.4ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 41.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 35.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 31.7ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 31.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 33.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 46.8ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 5.1ms preprocess, 46.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 38.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 33.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.3ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 35.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 43.5ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 43.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 43.1ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 43.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.7ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 36.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.5ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 39.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 32.9ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 32.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 52.2ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 52.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 45.1ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 45.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 47.6ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 47.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.6ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 2.4ms preprocess, 39.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 30.4ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 30.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 45.8ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 45.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 41.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 41.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 32.2ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 32.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 29.7ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 29.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.5ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 39.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.7ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 38.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.0ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 37.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 40.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 40.2ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 31.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 31.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 42.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 42.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 35.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 36.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 43.0ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 43.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.4ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 33.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 40.5ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 2.9ms preprocess, 40.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.1ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 35.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 46.7ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 46.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 166.2ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 166.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 53.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 53.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 43.2ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 43.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 64.3ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 2.6ms preprocess, 64.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.6ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 34.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.5ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 5.0ms preprocess, 33.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 33.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 77.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 77.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 3.9ms preprocess, 35.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 32.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 3.2ms preprocess, 32.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 5.8ms preprocess, 35.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 36.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 44.8ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 3.4ms preprocess, 44.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.8ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 36.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.2ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 37.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.4ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 33.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.4ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 37.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.8ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 33.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.3ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 4.4ms preprocess, 36.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 40.1ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 40.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 41.5ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 41.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 46.6ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 46.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 34.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.7ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 39.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.9ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 37.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 42.2ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 42.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.4ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 36.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.8ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 33.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 2.3ms preprocess, 37.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.8ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 35.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 56.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 56.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 36.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 3.9ms preprocess, 39.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 42.1ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 42.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 44.7ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 3.2ms preprocess, 44.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 50.0ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 50.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.1ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 37.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.8ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 39.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.5ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 2.8ms preprocess, 34.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.5ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 37.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 32.2ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 32.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.7ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 34.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 31.7ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 31.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 41.2ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 41.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 58.4ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 4.5ms preprocess, 58.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 51.2ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 51.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 2.2ms preprocess, 39.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 70.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 70.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 51.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 3.9ms preprocess, 51.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 50.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 50.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 49.6ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 49.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 67.0ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 3.9ms preprocess, 67.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 56.7ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 56.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.5ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 36.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 38.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 carrot, 35.8ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> carrot\n",
      "Speed: 1.5ms preprocess, 35.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 36.8ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> cell phone\n",
      "Speed: 1.6ms preprocess, 36.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.9ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 37.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 33.1ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 33.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 31.4ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 31.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 34.6ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 34.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 32.3ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Speed: 4.9ms preprocess, 32.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 31.9ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 31.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 33.7ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 33.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 33.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 33.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 37.2ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 37.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.9ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 36.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 29.3ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 29.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 33.9ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 33.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 43.9ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 43.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 34.7ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 34.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 34.1ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 34.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 29.7ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 29.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 34.9ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 34.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.5ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 34.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 85.9ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 85.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.4ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 33.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 31.0ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 31.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 34.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 34.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.2ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 2.7ms preprocess, 33.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 43.9ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 43.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 32.5ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 32.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 35.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 38.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 32.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Speed: 3.5ms preprocess, 32.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 32.7ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 32.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 35.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 32.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 32.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 34.5ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 34.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 32.6ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 32.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 37.8ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 37.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.7ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 35.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 32.0ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 32.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 34.3ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 34.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 32.9ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 32.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.5ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 35.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 39.9ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 39.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 32.4ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Speed: 3.2ms preprocess, 32.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 72.1ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 72.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 55.4ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Speed: 7.5ms preprocess, 55.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 46.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 46.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 46.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 2.8ms preprocess, 46.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 39.5ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 39.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.1ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 36.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 46.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 2.7ms preprocess, 46.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.7ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 36.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 34.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.5ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 34.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 29.6ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 29.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.5ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 35.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.8ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 37.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 33.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.6ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 38.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.5ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 35.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 47.0ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 47.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 42.6ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 42.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 82.1ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 82.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.2ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 3.2ms preprocess, 39.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.6ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 35.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.5ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 33.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 53.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 2.6ms preprocess, 53.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 35.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.3ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 4.1ms preprocess, 39.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.5ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 35.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.8ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 2.9ms preprocess, 36.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.6ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 34.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.5ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 34.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 40.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 4.4ms preprocess, 40.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 42.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 42.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 56.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 56.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 46.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 46.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.1ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 39.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 39.8ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 39.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.6ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 35.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 46.7ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 2.4ms preprocess, 46.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 32.5ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 4.7ms preprocess, 32.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 frisbee, 40.8ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> frisbee\n",
      "Speed: 16.6ms preprocess, 40.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 frisbee, 50.3ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> frisbee\n",
      "Speed: 1.5ms preprocess, 50.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 47.5ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 47.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 48.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 48.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 63.1ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 63.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 frisbee, 60.7ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> frisbee\n",
      "Speed: 1.5ms preprocess, 60.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 frisbee, 53.6ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> frisbee\n",
      "Speed: 2.3ms preprocess, 53.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.8ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 35.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.9ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 37.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.4ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 33.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 32.5ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 32.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.7ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 34.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 31.6ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 31.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.0ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 34.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 42.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 42.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.0ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 35.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.9ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 35.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.0ms\n",
      "Confianza ---> 0.96\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 34.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.4ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 34.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.4ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 38.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 2.9ms preprocess, 34.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 34.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 40.0ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 2.2ms preprocess, 40.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 43.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 43.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.7ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 5.0ms preprocess, 35.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 32.0ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 32.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.0ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 35.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 41.2ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 2.2ms preprocess, 41.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.3ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 36.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 32.6ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 32.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.0ms\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 38.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 45.3ms\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 45.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 43.8ms\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Speed: 3.9ms preprocess, 43.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.1ms\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 33.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.5ms\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 37.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 frisbee, 34.9ms\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> frisbee\n",
      "Speed: 1.6ms preprocess, 34.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 frisbee, 37.5ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> frisbee\n",
      "Speed: 1.4ms preprocess, 37.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.4ms\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 34.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.8ms\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 34.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.5ms\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 33.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.5ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 37.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 47.6ms\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 47.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 43.4ms\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Speed: 3.3ms preprocess, 43.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 41.6ms\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 41.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.4ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 39.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.2ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 39.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.7ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 38.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 60.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 60.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 41.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 41.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 29.8ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 29.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.6ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 39.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.5ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 34.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 43.0ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 43.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 53.7ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 53.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 47.0ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 4.7ms preprocess, 47.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 35.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 45.8ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 45.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.5ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 34.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 32.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 32.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.8ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 39.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 31.2ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 31.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 34.1ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 34.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 38.8ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Speed: 6.5ms preprocess, 38.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.5ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 5.0ms preprocess, 35.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.1ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 39.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.3ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 35.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 41.9ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 41.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 36.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 60.8ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> tie\n",
      "Speed: 3.2ms preprocess, 60.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 33.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.4ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 38.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 40.8ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 40.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 42.0ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 42.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 47.9ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 47.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.3ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 74.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 48.8ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 48.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 47.4ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 47.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 47.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 47.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 52.6ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 52.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 47.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 2.3ms preprocess, 47.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.5ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 36.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 35.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 33.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 32.6ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 32.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.5ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 2.9ms preprocess, 36.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 35.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 38.3ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> tie\n",
      "Speed: 1.5ms preprocess, 38.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 46.8ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 46.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 65.3ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 65.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 frisbee, 34.0ms\n",
      "Confianza ---> 0.95\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> frisbee\n",
      "Speed: 1.5ms preprocess, 34.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 34.8ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> cell phone\n",
      "Speed: 1.7ms preprocess, 34.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 30.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> cell phone\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 38.7ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> cell phone\n",
      "Speed: 2.2ms preprocess, 38.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 31.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> cell phone\n",
      "Speed: 1.7ms preprocess, 31.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 38.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 2.3ms preprocess, 33.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 frisbee, 32.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.74\n",
      "Clase --> frisbee\n",
      "Speed: 1.9ms preprocess, 32.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 35.4ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.75\n",
      "Clase --> tie\n",
      "Speed: 2.2ms preprocess, 35.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 32.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> tie\n",
      "Speed: 1.5ms preprocess, 32.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 41.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.6\n",
      "Clase --> tie\n",
      "Speed: 1.5ms preprocess, 41.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tie, 39.7ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.59\n",
      "Clase --> tie\n",
      "Speed: 1.4ms preprocess, 39.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.6ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 35.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 37.0ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> cell phone\n",
      "Speed: 1.6ms preprocess, 37.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 32.2ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 32.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 37.4ms\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "Confianza ---> 0.61\n",
      "Clase --> cell phone\n",
      "Speed: 1.4ms preprocess, 37.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 40.6ms\n",
      "Confianza ---> 0.73\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Speed: 6.1ms preprocess, 40.6ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 37.4ms\n",
      "Confianza ---> 0.82\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 37.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 35.1ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> cell phone\n",
      "Speed: 1.5ms preprocess, 35.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 33.8ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 33.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 39.5ms\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 39.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 34.2ms\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> cell phone\n",
      "Speed: 1.5ms preprocess, 34.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 58.9ms\n",
      "Confianza ---> 0.83\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "Speed: 5.8ms preprocess, 58.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 29.3ms\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 29.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 33.6ms\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "Confianza ---> 0.55\n",
      "Clase --> cell phone\n",
      "Speed: 1.4ms preprocess, 33.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 43.3ms\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> cell phone\n",
      "Speed: 1.7ms preprocess, 43.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 69.0ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.84\n",
      "Clase --> cell phone\n",
      "Speed: 2.1ms preprocess, 69.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 79.5ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.78\n",
      "Clase --> cell phone\n",
      "Speed: 1.6ms preprocess, 79.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 51.9ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.57\n",
      "Clase --> cell phone\n",
      "Speed: 1.6ms preprocess, 51.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 53.7ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> cell phone\n",
      "Speed: 1.5ms preprocess, 53.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 33.4ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 5.6ms preprocess, 33.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 39.0ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.56\n",
      "Clase --> cell phone\n",
      "Speed: 1.6ms preprocess, 39.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.7ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 35.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 37.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> cell phone\n",
      "Speed: 1.4ms preprocess, 37.9ms inference, 8.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 44.9ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.58\n",
      "Clase --> cell phone\n",
      "Speed: 1.4ms preprocess, 44.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 33.5ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.74\n",
      "Clase --> cell phone\n",
      "Speed: 1.6ms preprocess, 33.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 35.3ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.77\n",
      "Clase --> cell phone\n",
      "Speed: 1.5ms preprocess, 35.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 35.2ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.71\n",
      "Clase --> cell phone\n",
      "Speed: 1.9ms preprocess, 35.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 39.6ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.7\n",
      "Clase --> cell phone\n",
      "Speed: 1.6ms preprocess, 39.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 38.1ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> cell phone\n",
      "Speed: 1.5ms preprocess, 38.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 31.7ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> cell phone\n",
      "Speed: 1.9ms preprocess, 31.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 32.8ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.68\n",
      "Clase --> cell phone\n",
      "Speed: 1.6ms preprocess, 32.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 37.2ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 37.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 35.5ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.9\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 35.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 46.9ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 46.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 37.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "Speed: 6.2ms preprocess, 37.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 33.2ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.59\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 33.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 36.8ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.86\n",
      "Clase --> cell phone\n",
      "Speed: 1.5ms preprocess, 36.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 34.0ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> cell phone\n",
      "Speed: 1.8ms preprocess, 34.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.3ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 34.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 35.3ms\n",
      "Confianza ---> 0.64\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.59\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 35.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 30.1ms\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "Confianza ---> 0.67\n",
      "Clase --> cell phone\n",
      "Speed: 1.7ms preprocess, 30.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 32.4ms\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "Confianza ---> 0.79\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 32.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 38.7ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.8\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 38.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 35.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.65\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 35.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 34.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.69\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 34.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 32.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.46\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 32.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 47.8ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Speed: 3.7ms preprocess, 47.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 40.8ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.76\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 40.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 32.5ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 32.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 36.0ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.81\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 36.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 33.3ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.81\n",
      "Clase --> cell phone\n",
      "Speed: 1.6ms preprocess, 33.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 34.1ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.82\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 34.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 39.7ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.82\n",
      "Clase --> cell phone\n",
      "Speed: 1.8ms preprocess, 39.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 35.3ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.87\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 35.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 32.2ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.89\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 32.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 42.3ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.86\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Speed: 5.1ms preprocess, 42.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 46.7ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.85\n",
      "Clase --> cell phone\n",
      "Speed: 2.2ms preprocess, 46.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 34.9ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.87\n",
      "Clase --> cell phone\n",
      "Speed: 1.8ms preprocess, 34.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 44.8ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.87\n",
      "Clase --> cell phone\n",
      "Speed: 1.6ms preprocess, 44.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 35.7ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.79\n",
      "Clase --> cell phone\n",
      "Speed: 1.5ms preprocess, 35.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 33.9ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.77\n",
      "Clase --> cell phone\n",
      "Speed: 1.5ms preprocess, 33.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 32.9ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.78\n",
      "Clase --> cell phone\n",
      "Speed: 1.5ms preprocess, 32.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 36.5ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.85\n",
      "Clase --> cell phone\n",
      "Speed: 1.8ms preprocess, 36.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 36.5ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.86\n",
      "Clase --> cell phone\n",
      "Speed: 2.0ms preprocess, 36.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 38.2ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.76\n",
      "Clase --> cell phone\n",
      "Speed: 1.8ms preprocess, 38.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 35.1ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.78\n",
      "Clase --> cell phone\n",
      "Speed: 2.1ms preprocess, 35.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 35.1ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.82\n",
      "Clase --> cell phone\n",
      "Speed: 1.4ms preprocess, 35.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 40.6ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.87\n",
      "Clase --> cell phone\n",
      "Speed: 2.1ms preprocess, 40.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 34.5ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.79\n",
      "Clase --> cell phone\n",
      "Speed: 4.4ms preprocess, 34.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 33.7ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.75\n",
      "Clase --> cell phone\n",
      "Speed: 1.8ms preprocess, 33.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 34.4ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 34.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 36.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 36.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 43.8ms\n",
      "Confianza ---> 0.95\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 43.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 75.7ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 75.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 35.9ms\n",
      "Confianza ---> 0.95\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 35.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 2 cell phones, 38.4ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.61\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.53\n",
      "Clase --> cell phone\n",
      "Speed: 1.8ms preprocess, 38.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 37.4ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.8\n",
      "Clase --> cell phone\n",
      "Speed: 1.5ms preprocess, 37.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 41.8ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.83\n",
      "Clase --> cell phone\n",
      "Speed: 1.7ms preprocess, 41.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 32.4ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.83\n",
      "Clase --> cell phone\n",
      "Speed: 1.5ms preprocess, 32.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 36.7ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.66\n",
      "Clase --> cell phone\n",
      "Speed: 1.6ms preprocess, 36.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 33.0ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> cell phone\n",
      "Speed: 1.4ms preprocess, 33.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 35.6ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> cell phone\n",
      "Speed: 1.8ms preprocess, 35.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 34.0ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.61\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 34.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 34.4ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.74\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 34.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 38.5ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.81\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 38.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 33.8ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.7\n",
      "Clase --> cell phone\n",
      "Speed: 1.5ms preprocess, 33.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 33.7ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 2.6ms preprocess, 33.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 42.4ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 42.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 36.8ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.67\n",
      "Clase --> cell phone\n",
      "Speed: 1.6ms preprocess, 36.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 38.0ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> cell phone\n",
      "Speed: 2.1ms preprocess, 38.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 35.4ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> cell phone\n",
      "Speed: 1.4ms preprocess, 35.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 31.7ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> cell phone\n",
      "Speed: 2.1ms preprocess, 31.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 29.4ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 29.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 33.4ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> cell phone\n",
      "Speed: 1.4ms preprocess, 33.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 33.7ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> cell phone\n",
      "Speed: 1.6ms preprocess, 33.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 33.7ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.56\n",
      "Clase --> cell phone\n",
      "Speed: 1.7ms preprocess, 33.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 37.3ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> cell phone\n",
      "Speed: 1.8ms preprocess, 37.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 32.1ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> cell phone\n",
      "Speed: 1.7ms preprocess, 32.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 29.5ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> cell phone\n",
      "Speed: 1.7ms preprocess, 29.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 34.8ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> cell phone\n",
      "Speed: 1.4ms preprocess, 34.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 47.9ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> cell phone\n",
      "Speed: 4.6ms preprocess, 47.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 62.0ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> cell phone\n",
      "Speed: 2.2ms preprocess, 62.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 35.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.65\n",
      "Clase --> cell phone\n",
      "Speed: 1.6ms preprocess, 35.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 32.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.76\n",
      "Clase --> cell phone\n",
      "Speed: 1.6ms preprocess, 32.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 37.3ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.79\n",
      "Clase --> cell phone\n",
      "Speed: 1.6ms preprocess, 37.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 35.5ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.73\n",
      "Clase --> cell phone\n",
      "Speed: 1.6ms preprocess, 35.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 32.6ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.71\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 32.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 cell phone, 33.0ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.8\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 33.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bottle, 1 cell phone, 32.7ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> bottle\n",
      "Confianza ---> 0.26\n",
      "Clase --> cell phone\n",
      "Speed: 1.6ms preprocess, 32.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 bottle, 39.2ms\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "Confianza ---> 0.59\n",
      "Clase --> bottle\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Speed: 2.9ms preprocess, 39.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 book, 66.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.62\n",
      "Clase --> book\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 66.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 45.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 45.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 33.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 33.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 36.4ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.46\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 36.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.8ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 36.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 36.7ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.54\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 36.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 40.8ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 40.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 36.8ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 36.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 35.9ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 35.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 37.2ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 37.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 38.0ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 38.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 36.2ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 36.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 54.6ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.58\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 54.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 43.0ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Speed: 2.2ms preprocess, 43.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.3ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.59\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 35.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.5ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.56\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 35.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 49.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Speed: 3.8ms preprocess, 49.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 33.8ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 33.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 33.5ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 33.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 32.8ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 32.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.8ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 35.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 33.8ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 33.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 34.0ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 34.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 42.5ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 42.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 33.3ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 33.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.6ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 36.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 38.5ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 38.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.9ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 35.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 46.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 46.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.2ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 36.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 54.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 54.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 40.2ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 40.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 36.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 42.8ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 42.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 53.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 53.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 75.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 75.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 41.6ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Speed: 2.2ms preprocess, 41.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 38.1ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 38.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 52.2ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 52.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 48.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 48.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 54.3ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 54.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.9ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Speed: 2.3ms preprocess, 36.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 39.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 39.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 37.4ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 37.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 37.2ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "Speed: 2.4ms preprocess, 37.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 42.7ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 42.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.1ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Speed: 4.6ms preprocess, 35.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 40.2ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.58\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 40.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 31.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 31.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 35.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 37.1ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 37.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 41.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.54\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 41.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 40.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 40.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 89.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 89.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 34.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 34.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 40.7ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 40.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 37.6ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.46\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 37.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 33.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 33.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 45.4ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 45.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.9ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 36.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.1ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 37.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 40.2ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 40.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 67.1ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 67.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 51.5ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 51.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 40.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 40.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 50.5ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 50.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.4ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 36.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 35.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 41.5ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 41.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 2.6ms preprocess, 37.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 50.7ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 50.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 49.4ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 3.0ms preprocess, 49.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 39.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 36.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 44.8ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 44.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.4ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 38.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.7ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 38.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 44.8ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 44.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.6ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 39.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 31.9ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 31.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 108.9ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 8.5ms preprocess, 108.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 35.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.6ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 34.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 44.0ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.2ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 34.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.7ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 36.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 31.6ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 31.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 66.0ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 3.1ms preprocess, 66.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 39.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "Speed: 2.2ms preprocess, 39.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.4ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 38.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.1ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 10.9ms preprocess, 35.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.8ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 59.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 41.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 41.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.3ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 38.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 67.8ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 67.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.2ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 35.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.0ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 3.2ms preprocess, 38.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.0ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 34.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.7ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 2.3ms preprocess, 39.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.1ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 39.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.2ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 34.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 43.2ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 43.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.5ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 33.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 40.8ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 3.8ms preprocess, 40.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 37.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 36.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 40.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 40.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.6ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 38.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 44.8ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 44.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.5ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 35.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.2ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 38.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.5ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 34.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 59.6ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 59.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.4ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 37.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.3ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 38.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.6ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 33.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 40.9ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 40.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 38.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 38.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 34.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 34.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 44.3ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 2.9ms preprocess, 44.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 69.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 69.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.1ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 38.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.8ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 33.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.5ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 2.3ms preprocess, 35.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 36.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.9ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 35.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.5ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.6\n",
      "Clase --> person\n",
      "Speed: 9.2ms preprocess, 36.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 32.8ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.54\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 32.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 41.0ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "Speed: 2.3ms preprocess, 41.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 44.3ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 44.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 32.0ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 32.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 33.0ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.58\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 33.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 33.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 33.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 31.4ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 31.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.2ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 35.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 34.4ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 34.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 44.3ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "Speed: 7.3ms preprocess, 44.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.0ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 36.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 38.3ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 38.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 58.5ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 58.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 45.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 45.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 41.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 41.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 38.8ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 38.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.3ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 36.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 35.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 35.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 34.7ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 34.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 34.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Speed: 5.1ms preprocess, 34.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 33.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 33.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 32.8ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 32.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 69.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Speed: 2.8ms preprocess, 69.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 36.6ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 36.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 72.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 72.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 36.5ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 36.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 33.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 33.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 34.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 34.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 44.6ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Speed: 5.6ms preprocess, 44.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 40.5ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Speed: 3.1ms preprocess, 40.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 34.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 34.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 31.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 31.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 35.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Speed: 2.9ms preprocess, 35.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 53.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.56\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 2.6ms preprocess, 53.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 32.7ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 32.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 40.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.56\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 40.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 32.8ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 32.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 31.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 31.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 41.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 41.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 30.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 30.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 34.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 41.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 2.6ms preprocess, 41.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 38.9ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 38.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 40.6ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 40.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 36.9ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.5ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 35.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 37.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 37.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.6ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 39.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 32.7ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 32.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 36.6ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 2.2ms preprocess, 36.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 35.8ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 35.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 45.7ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 45.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 33.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 34.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 34.8ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 34.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 50.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 50.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 40.7ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 3.4ms preprocess, 40.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 34.7ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 34.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 42.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 42.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 36.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 36.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 36.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 36.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 34.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 34.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 35.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 35.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 35.6ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 35.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 37.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 3.6ms preprocess, 37.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 33.7ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 33.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 45.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 45.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 39.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 39.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 32.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 32.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 74.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Speed: 2.6ms preprocess, 74.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 64.5ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 2.3ms preprocess, 64.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 41.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.46\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 41.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 41.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 41.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 50.8ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 50.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 57.8ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 57.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 64.7ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.54\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 64.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 54.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.54\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 54.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 41.5ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.54\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 41.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 31.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 31.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 41.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 41.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 36.7ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.54\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 36.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 33.8ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 33.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 30.5ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 30.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 34.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 34.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 39.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.56\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 39.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 34.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 34.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 30.7ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 30.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 33.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 33.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 33.4ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.58\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 3.4ms preprocess, 33.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 44.7ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.56\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 44.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 55.7ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 55.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 52.3ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.54\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 52.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 68.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 68.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 63.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 63.1ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 48.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.59\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 48.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 43.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 43.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 58.7ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.59\n",
      "Clase --> person\n",
      "Confianza ---> 0.46\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 58.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 41.5ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 41.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 68.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.58\n",
      "Clase --> person\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 68.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 37.5ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 37.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 41.7ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 41.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 42.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 42.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 36.7ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 36.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 34.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.58\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 34.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 33.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 33.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 33.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 33.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 33.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 33.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 35.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 35.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 31.2ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 31.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 36.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 36.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 35.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 35.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 cell phone, 32.8ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.46\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 32.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 cell phone, 39.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.57\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.46\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 39.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 35.0ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 35.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 tie, 38.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> tie\n",
      "Speed: 1.6ms preprocess, 38.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 cell phone, 49.3ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.61\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 49.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 toothbrush, 40.1ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> toothbrush\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 40.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 30.4ms\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "Confianza ---> 0.54\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 30.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 46.2ms\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "Speed: 18.0ms preprocess, 46.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 cell phone, 101.4ms\n",
      "Confianza ---> 0.77\n",
      "Clase --> person\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "Confianza ---> 0.46\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> cell phone\n",
      "Speed: 3.4ms preprocess, 101.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 cell phone, 55.8ms\n",
      "Confianza ---> 0.79\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Confianza ---> 0.59\n",
      "Clase --> person\n",
      "Confianza ---> 0.54\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 2.2ms preprocess, 55.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 cell phone, 38.2ms\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "Confianza ---> 0.63\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 38.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 cell phone, 32.8ms\n",
      "Confianza ---> 0.78\n",
      "Clase --> person\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Speed: 2.8ms preprocess, 32.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 cell phone, 33.5ms\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "Confianza ---> 0.56\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 33.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 2 cell phones, 39.4ms\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.35\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 39.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 3 cell phones, 44.5ms\n",
      "Confianza ---> 0.82\n",
      "Clase --> person\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.45\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.39\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 44.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 skateboard, 3 cell phones, 60.4ms\n",
      "Confianza ---> 0.54\n",
      "Clase --> person\n",
      "Confianza ---> 0.51\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.42\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.39\n",
      "Clase --> skateboard\n",
      "Confianza ---> 0.33\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 60.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 cell phone, 37.7ms\n",
      "Confianza ---> 0.76\n",
      "Clase --> person\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Confianza ---> 0.46\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 2.6ms preprocess, 37.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 cell phone, 34.0ms\n",
      "Confianza ---> 0.83\n",
      "Clase --> person\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 34.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 cell phone, 31.7ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> person\n",
      "Confianza ---> 0.54\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 31.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 cell phone, 53.5ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.6\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 3.4ms preprocess, 53.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 zebra, 2 cell phones, 34.3ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.3\n",
      "Clase --> cell phone\n",
      "Speed: 1.5ms preprocess, 34.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 zebra, 1 cell phone, 40.7ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "Confianza ---> 0.56\n",
      "Clase --> person\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> cell phone\n",
      "Speed: 1.4ms preprocess, 40.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 zebra, 2 cell phones, 36.4ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.8\n",
      "Clase --> person\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.27\n",
      "Clase --> cell phone\n",
      "Speed: 2.2ms preprocess, 36.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 zebra, 1 cell phone, 39.2ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "Confianza ---> 0.6\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 39.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 zebra, 32.8ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 32.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 zebra, 3 cell phones, 35.5ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "Confianza ---> 0.6\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.28\n",
      "Clase --> cell phone\n",
      "Speed: 1.5ms preprocess, 35.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 zebra, 3 cell phones, 36.2ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.89\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Confianza ---> 0.51\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.46\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> cell phone\n",
      "Speed: 1.6ms preprocess, 36.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 zebra, 3 cell phones, 34.6ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.89\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.74\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.44\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 34.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 zebra, 3 cell phones, 48.5ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.89\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "Confianza ---> 0.62\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.53\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 5.5ms preprocess, 48.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 zebra, 4 cell phones, 58.9ms\n",
      "Confianza ---> 0.96\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.82\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Confianza ---> 0.62\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.33\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 7.8ms preprocess, 58.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 zebra, 3 cell phones, 32.1ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.87\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Confianza ---> 0.43\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.42\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 2.2ms preprocess, 32.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 zebra, 3 cell phones, 32.0ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.9\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.57\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.55\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.54\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 32.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 zebra, 3 cell phones, 40.1ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.82\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.67\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.59\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> cell phone\n",
      "Speed: 1.6ms preprocess, 40.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 zebra, 2 cell phones, 39.4ms\n",
      "Confianza ---> 0.78\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 39.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 zebra, 2 cell phones, 38.2ms\n",
      "Confianza ---> 0.75\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.67\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 38.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 zebra, 2 cell phones, 37.7ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.55\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 37.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 zebra, 2 cell phones, 44.1ms\n",
      "Confianza ---> 0.78\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 44.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 zebra, 3 cell phones, 34.2ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.28\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 34.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 zebra, 1 cell phone, 33.3ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.56\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 33.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 zebra, 1 cell phone, 40.1ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 40.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 3 cell phones, 44.7ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.87\n",
      "Clase --> person\n",
      "Confianza ---> 0.63\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.32\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.3\n",
      "Clase --> cell phone\n",
      "Speed: 2.0ms preprocess, 44.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 zebra, 2 cell phones, 62.5ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.86\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.55\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> cell phone\n",
      "Speed: 1.7ms preprocess, 62.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 2 zebras, 2 cell phones, 36.7ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.75\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.71\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.61\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 36.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 zebra, 2 cell phones, 34.1ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.84\n",
      "Clase --> person\n",
      "Confianza ---> 0.84\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.64\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 34.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 zebra, 2 cell phones, 44.6ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.85\n",
      "Clase --> person\n",
      "Confianza ---> 0.79\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> cell phone\n",
      "Speed: 1.9ms preprocess, 44.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 zebra, 2 cell phones, 34.8ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "Confianza ---> 0.71\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.48\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 34.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 zebra, 2 cell phones, 35.6ms\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "Confianza ---> 0.81\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.78\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> cell phone\n",
      "Speed: 4.1ms preprocess, 35.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 zebra, 2 cell phones, 46.1ms\n",
      "Confianza ---> 0.83\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.81\n",
      "Clase --> person\n",
      "Confianza ---> 0.69\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.58\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "Speed: 2.4ms preprocess, 46.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 zebra, 2 cell phones, 42.6ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.8\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.76\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 42.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 zebra, 2 cell phones, 37.5ms\n",
      "Confianza ---> 0.84\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.59\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.51\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 37.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 zebra, 1 cell phone, 72.6ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.65\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 72.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 zebra, 1 cell phone, 38.5ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.65\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "Confianza ---> 0.56\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 38.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 zebra, 1 cell phone, 36.8ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.61\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 36.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 zebra, 1 cell phone, 38.9ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.67\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Confianza ---> 0.36\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 38.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 zebra, 2 cell phones, 65.2ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.6\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Speed: 2.3ms preprocess, 65.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 zebra, 2 cell phones, 36.5ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "Confianza ---> 0.55\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> cell phone\n",
      "Speed: 2.1ms preprocess, 36.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 zebra, 2 cell phones, 37.0ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.62\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.58\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> cell phone\n",
      "Speed: 2.2ms preprocess, 37.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 zebra, 1 cell phone, 36.2ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.56\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.56\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 36.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 zebra, 1 cell phone, 41.6ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 41.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 zebra, 1 cell phone, 34.8ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.64\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 34.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 zebra, 1 cell phone, 36.2ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.73\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 36.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 zebra, 1 cell phone, 36.0ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.63\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 36.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 zebra, 1 tv, 1 cell phone, 33.6ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.68\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.61\n",
      "Clase --> person\n",
      "Confianza ---> 0.6\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> tvmonitor\n",
      "Speed: 1.9ms preprocess, 33.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 zebra, 1 tv, 2 cell phones, 33.7ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "Confianza ---> 0.51\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.36\n",
      "Clase --> tvmonitor\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> cell phone\n",
      "Speed: 2.2ms preprocess, 33.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 zebra, 1 tv, 1 cell phone, 39.8ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "Confianza ---> 0.58\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.34\n",
      "Clase --> tvmonitor\n",
      "Confianza ---> 0.31\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 39.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 1 tv, 1 cell phone, 48.8ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.7\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> tvmonitor\n",
      "Speed: 1.4ms preprocess, 48.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 1 cell phone, 39.7ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.65\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.59\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 39.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 zebra, 1 tv, 2 cell phones, 42.3ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.56\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> tvmonitor\n",
      "Speed: 2.9ms preprocess, 42.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 1 tv, 2 cell phones, 38.0ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.59\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.56\n",
      "Clase --> person\n",
      "Confianza ---> 0.35\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.31\n",
      "Clase --> tvmonitor\n",
      "Speed: 1.5ms preprocess, 38.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 1 tv, 2 cell phones, 38.4ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.66\n",
      "Clase --> person\n",
      "Confianza ---> 0.59\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.43\n",
      "Clase --> tvmonitor\n",
      "Confianza ---> 0.29\n",
      "Clase --> cell phone\n",
      "Speed: 1.9ms preprocess, 38.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 1 tv, 1 cell phone, 41.2ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.66\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> tvmonitor\n",
      "Speed: 2.2ms preprocess, 41.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 2 cell phones, 44.7ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.62\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.58\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> cell phone\n",
      "Speed: 1.7ms preprocess, 44.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 1 orange, 1 tv, 1 cell phone, 39.7ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.64\n",
      "Clase --> person\n",
      "Confianza ---> 0.57\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.4\n",
      "Clase --> orange\n",
      "Confianza ---> 0.33\n",
      "Clase --> tvmonitor\n",
      "Speed: 1.6ms preprocess, 39.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 1 cell phone, 33.6ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.72\n",
      "Clase --> person\n",
      "Confianza ---> 0.7\n",
      "Clase --> cell phone\n",
      "Speed: 1.6ms preprocess, 33.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 1 cell phone, 39.3ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.67\n",
      "Clase --> person\n",
      "Confianza ---> 0.63\n",
      "Clase --> cell phone\n",
      "Speed: 1.5ms preprocess, 39.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 1 cell phone, 35.0ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "Confianza ---> 0.65\n",
      "Clase --> cell phone\n",
      "Speed: 1.5ms preprocess, 35.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 1 cell phone, 42.1ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.74\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 42.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 1 tv, 1 cell phone, 36.9ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "Confianza ---> 0.57\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.3\n",
      "Clase --> tvmonitor\n",
      "Speed: 1.6ms preprocess, 36.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 1 cell phone, 34.3ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.68\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 34.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 1 tv, 1 cell phone, 44.0ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.75\n",
      "Clase --> person\n",
      "Confianza ---> 0.64\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.37\n",
      "Clase --> tvmonitor\n",
      "Speed: 1.5ms preprocess, 44.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 1 tv, 2 cell phones, 39.8ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.71\n",
      "Clase --> person\n",
      "Confianza ---> 0.51\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.39\n",
      "Clase --> tvmonitor\n",
      "Confianza ---> 0.26\n",
      "Clase --> cell phone\n",
      "Speed: 1.8ms preprocess, 39.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 1 tv, 1 cell phone, 35.5ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "Confianza ---> 0.59\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.41\n",
      "Clase --> tvmonitor\n",
      "Speed: 1.5ms preprocess, 35.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 1 tv, 1 cell phone, 35.4ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.7\n",
      "Clase --> person\n",
      "Confianza ---> 0.63\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.47\n",
      "Clase --> tvmonitor\n",
      "Speed: 1.5ms preprocess, 35.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 1 tv, 1 cell phone, 37.0ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "Confianza ---> 0.67\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.39\n",
      "Clase --> tvmonitor\n",
      "Speed: 1.5ms preprocess, 37.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 1 tv, 1 cell phone, 33.6ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "Confianza ---> 0.66\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.29\n",
      "Clase --> tvmonitor\n",
      "Speed: 1.6ms preprocess, 33.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 1 tv, 1 cell phone, 35.8ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Confianza ---> 0.62\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.28\n",
      "Clase --> tvmonitor\n",
      "Speed: 1.7ms preprocess, 35.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 1 cell phone, 34.4ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Confianza ---> 0.62\n",
      "Clase --> cell phone\n",
      "Speed: 1.6ms preprocess, 34.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 1 cell phone, 31.1ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.7\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 31.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 1 cell phone, 32.1ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.65\n",
      "Clase --> person\n",
      "Confianza ---> 0.65\n",
      "Clase --> cell phone\n",
      "Speed: 1.7ms preprocess, 32.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 1 cell phone, 44.6ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.63\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 44.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 3 cell phones, 32.5ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.58\n",
      "Clase --> person\n",
      "Confianza ---> 0.56\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.34\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.31\n",
      "Clase --> cell phone\n",
      "Speed: 1.5ms preprocess, 32.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 1 cell phone, 34.3ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.63\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.59\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 34.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 zebra, 1 cell phone, 45.3ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.74\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.59\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 45.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 1 cell phone, 34.3ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.69\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.63\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 34.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 1 cell phone, 46.8ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.7\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 46.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 1 cell phone, 63.0ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.7\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.69\n",
      "Clase --> person\n",
      "Speed: 5.5ms preprocess, 63.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 2 cell phones, 34.8ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.73\n",
      "Clase --> person\n",
      "Confianza ---> 0.69\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.35\n",
      "Clase --> cell phone\n",
      "Speed: 1.6ms preprocess, 34.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 2 cell phones, 31.0ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.73\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.68\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> cell phone\n",
      "Speed: 1.5ms preprocess, 31.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 zebra, 1 cell phone, 36.5ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.72\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.51\n",
      "Clase --> person\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 36.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 zebra, 1 tv, 1 cell phone, 40.6ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.76\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.58\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> tvmonitor\n",
      "Speed: 1.8ms preprocess, 40.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 1 tv, 1 cell phone, 36.6ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.39\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.35\n",
      "Clase --> tvmonitor\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 2.2ms preprocess, 36.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 1 cell phone, 34.9ms\n",
      "Confianza ---> 0.77\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.34\n",
      "Clase --> person\n",
      "Confianza ---> 0.32\n",
      "Clase --> cell phone\n",
      "Speed: 2.3ms preprocess, 34.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 zebra, 34.7ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> zebra\n",
      "Speed: 4.7ms preprocess, 34.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 36.7ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 36.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 zebra, 38.2ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> zebra\n",
      "Speed: 1.9ms preprocess, 38.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 31.6ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.35\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 31.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 39.5ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 39.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 42.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 3.4ms preprocess, 42.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 36.9ms\n",
      "Confianza ---> 0.95\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.33\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 36.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 zebra, 1 cell phone, 40.5ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.29\n",
      "Clase --> cell phone\n",
      "Speed: 1.6ms preprocess, 40.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 zebra, 1 tv, 1 cell phone, 34.3ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.67\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.33\n",
      "Clase --> tvmonitor\n",
      "Speed: 2.3ms preprocess, 34.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 zebra, 33.6ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> zebra\n",
      "Speed: 1.5ms preprocess, 33.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 zebra, 1 tv, 51.7ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.41\n",
      "Clase --> tvmonitor\n",
      "Speed: 1.7ms preprocess, 51.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 zebra, 1 tv, 44.2ms\n",
      "Confianza ---> 0.85\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.33\n",
      "Clase --> tvmonitor\n",
      "Speed: 1.4ms preprocess, 44.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 zebra, 1 tv, 44.6ms\n",
      "Confianza ---> 0.85\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.36\n",
      "Clase --> tvmonitor\n",
      "Speed: 1.6ms preprocess, 44.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 zebra, 1 tv, 30.5ms\n",
      "Confianza ---> 0.84\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.39\n",
      "Clase --> tvmonitor\n",
      "Speed: 4.2ms preprocess, 30.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 1 laptop, 36.2ms\n",
      "Confianza ---> 0.82\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.37\n",
      "Clase --> laptop\n",
      "Confianza ---> 0.29\n",
      "Clase --> person\n",
      "Speed: 3.4ms preprocess, 36.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 1 tv, 1 laptop, 46.4ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "Confianza ---> 0.37\n",
      "Clase --> laptop\n",
      "Confianza ---> 0.33\n",
      "Clase --> tvmonitor\n",
      "Speed: 2.2ms preprocess, 46.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 41.3ms\n",
      "Confianza ---> 0.82\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Speed: 2.4ms preprocess, 41.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 1 cell phone, 34.7ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Confianza ---> 0.4\n",
      "Clase --> cell phone\n",
      "Speed: 1.6ms preprocess, 34.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 zebra, 1 cell phone, 34.9ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.47\n",
      "Clase --> cell phone\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.26\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 34.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 44.6ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.54\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 44.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 44.9ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 44.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 31.0ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 31.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 50.3ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 50.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 50.8ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "Speed: 3.8ms preprocess, 50.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 50.5ms\n",
      "Confianza ---> 0.87\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 50.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 43.6ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.39\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 43.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 44.6ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 44.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 1 tv, 55.7ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.32\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> tvmonitor\n",
      "Speed: 1.6ms preprocess, 55.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 45.0ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.38\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 45.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 1 tv, 40.7ms\n",
      "Confianza ---> 0.89\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.43\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> tvmonitor\n",
      "Speed: 1.7ms preprocess, 40.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 55.5ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.46\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 55.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 1 tv, 40.2ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.37\n",
      "Clase --> person\n",
      "Confianza ---> 0.3\n",
      "Clase --> tvmonitor\n",
      "Speed: 1.5ms preprocess, 40.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 zebra, 1 cell phone, 84.2ms\n",
      "Confianza ---> 0.86\n",
      "Clase --> zebra\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> cell phone\n",
      "Speed: 2.2ms preprocess, 84.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 tennis racket, 51.3ms\n",
      "Confianza ---> 0.88\n",
      "Clase --> person\n",
      "Confianza ---> 0.38\n",
      "Clase --> tennis racket\n",
      "Speed: 1.6ms preprocess, 51.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.3ms\n",
      "Confianza ---> 0.91\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 76.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 44.9ms\n",
      "Confianza ---> 0.9\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 44.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 39.7ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 39.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 33.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 33.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 44.5ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 44.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 40.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 40.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 44.8ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 44.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 34.5ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.54\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 34.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 43.6ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "Speed: 2.1ms preprocess, 43.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 31.7ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 31.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 37.5ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.45\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 35.3ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.49\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 35.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 41.4ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.44\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 41.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 37.5ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.41\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 37.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.7ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.42\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 36.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 38.7ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.46\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 38.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 51.1ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.47\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 51.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 40.9ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 40.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 41.2ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Speed: 2.5ms preprocess, 41.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.2ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.62\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 36.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 35.0ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.56\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 1.7ms preprocess, 35.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 82.6ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.56\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 82.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 39.7ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 39.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 38.5ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Confianza ---> 0.27\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 38.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 33.6ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 33.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 32.9ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.56\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 32.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 38.6ms\n",
      "Confianza ---> 0.92\n",
      "Clase --> person\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 38.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 44.9ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.52\n",
      "Clase --> person\n",
      "Speed: 2.0ms preprocess, 44.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 41.6ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 41.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 37.1ms\n",
      "Confianza ---> 0.93\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 37.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 42.0ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.59\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 42.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 40.7ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.56\n",
      "Clase --> person\n",
      "Speed: 2.2ms preprocess, 40.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 39.8ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.58\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 39.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 64.8ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.53\n",
      "Clase --> person\n",
      "Speed: 1.9ms preprocess, 64.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 36.6ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.5\n",
      "Clase --> person\n",
      "Speed: 2.9ms preprocess, 36.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 42.2ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "Speed: 1.5ms preprocess, 42.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 33.0ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.55\n",
      "Clase --> person\n",
      "Speed: 1.4ms preprocess, 33.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 42.4ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.48\n",
      "Clase --> person\n",
      "Confianza ---> 0.28\n",
      "Clase --> person\n",
      "Speed: 1.8ms preprocess, 42.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 45.8ms\n",
      "Confianza ---> 0.94\n",
      "Clase --> person\n",
      "Confianza ---> 0.57\n",
      "Clase --> person\n",
      "Speed: 1.6ms preprocess, 45.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mEl kernel se bloqueó al ejecutar código en la celda actual o en una celda anterior. \n",
      "\u001b[1;31mRevise el código de las celdas para identificar una posible causa del error. \n",
      "\u001b[1;31mHaga clic <a href='https://aka.ms/vscodeJupyterKernelCrash'>aquí</a> para obtener más información. \n",
      "\u001b[1;31mVea Jupyter <a href='command:jupyter.viewOutput'>log</a> para obtener más detalles."
     ]
    }
   ],
   "source": [
    "# Carga del modelo, descarga en disco si no está presente en la carpeta\n",
    "model = YOLO('yolo11n.pt') #Contenedores\n",
    "\n",
    "# Etiqueta de las distintas clases\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ]\n",
    "\n",
    "\n",
    "# Captura desde la webcam\n",
    "vid = cv2.VideoCapture(0)\n",
    "  \n",
    "while(True):      \n",
    "    # fotograma a fotograma\n",
    "    ret, img = vid.read()\n",
    "  \n",
    "    # si hay imagen válida\n",
    "    if ret:  \n",
    "        # Detecta en la imagen\n",
    "        results = model(img, stream=True)\n",
    "        \n",
    "        # Para cada detección\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "\n",
    "            for box in boxes:\n",
    "                # Contenedor\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
    "                \n",
    "                # Confianza\n",
    "                confidence = math.ceil((box.conf[0]*100))/100\n",
    "                print(\"Confianza --->\",confidence)\n",
    "\n",
    "                # Clase\n",
    "                cls = int(box.cls[0])\n",
    "                print(\"Clase -->\", classNames[cls])\n",
    "\n",
    "                # Convierte identificador numérico de clase a un color RGB\n",
    "                escala = int((cls / len(classNames)) * 255 * 3)\n",
    "                if escala >= 255*2:\n",
    "                    R = 255\n",
    "                    G = 255\n",
    "                    B = escala - 255*2\n",
    "                else:\n",
    "                    if escala >= 255:\n",
    "                        R = 255\n",
    "                        G = escala - 255\n",
    "                        B = 0\n",
    "                    else:\n",
    "                        R = escala\n",
    "                        G = 0\n",
    "                        B = 0\n",
    "\n",
    "                # Dibuja el contenedor y clase\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (R, G, B), 3)\n",
    "                cv2.putText(img, classNames[cls] , [x1, y1], cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, B), 2)\n",
    "\n",
    "        # Muestra fotograma\n",
    "        cv2.imshow('Vid', img)\n",
    "    \n",
    "    # Detenemos pulsado ESC\n",
    "    if cv2.waitKey(20) == 27:\n",
    "        break\n",
    "  \n",
    "# Libera el objeto de captura\n",
    "vid.release()\n",
    "# Destruye ventanas\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguimiento. Requiere instalar lap con pip install lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# Carga del modelo, descarga en disco si no está presente en la carpeta\n",
    "model = YOLO('yolo11n.pt') #Contenedores\n",
    "\n",
    "# Etiqueta de las distintas clases\n",
    "classNames = [\"person\", \"bicycle\", \"car\"]\n",
    "\n",
    "\n",
    "# Captura desde la webcam\n",
    "vid = cv2.VideoCapture(0)\n",
    "track_history = defaultdict(lambda: [])\n",
    "  \n",
    "while(True):      \n",
    "    # fotograma a fotograma\n",
    "    ret, img = vid.read()\n",
    "  \n",
    "    # si hay imagen válida\n",
    "    if ret:  \n",
    "        # Seguimiento, con persistencia entre fotogramas\n",
    "        results = model.track(img, persist=True, classes = [0,1,2])\n",
    "\n",
    "        if 0:\n",
    "            if results is not None:\n",
    "                print(results[0])\n",
    "                boxes = results[0].boxes.xywh.cpu()\n",
    "                track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "                annotated_frame = results[0].plot()\n",
    "                for box, track_id in zip(boxes, track_ids):\n",
    "                    x, y, w, h = box\n",
    "                    track = track_history[track_id]\n",
    "                    track.append((float(x), float(y)))\n",
    "                    if len(track) > 30:\n",
    "                        track.pop(0)\n",
    "                    points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))\n",
    "                    cv2.polylines(annotated_frame, [points], isClosed=False, color=(230, 230, 230), thickness=10)\n",
    "                cv2.imshow(\"YOLO11 Tracking\", annotated_frame)\n",
    "                if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                    break\n",
    "        \n",
    "\n",
    "        \n",
    "        # Para cada detección\n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "\n",
    "            for box in boxes:\n",
    "                # Contenedor\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
    "\n",
    "                #Etiqueta de seguimiento\n",
    "                if box.id is not None:\n",
    "                    track_id = str(int(box.id[0].tolist()))\n",
    "                else:\n",
    "                    track_id = ''\n",
    "                \n",
    "                # Confianza\n",
    "                confidence = math.ceil((box.conf[0]*100))/100\n",
    "                print(\"Confianza --->\",confidence)\n",
    "\n",
    "                # Clase\n",
    "                cls = int(box.cls[0])\n",
    "                print(\"Clase -->\", classNames[cls])\n",
    "\n",
    "                # Convierte identificador numérico de clase a un color RGB\n",
    "                escala = int((cls / len(classNames)) * 255 * 3)\n",
    "                if escala >= 255*2:\n",
    "                    R = 255\n",
    "                    G = 255\n",
    "                    B = escala - 255*2\n",
    "                else:\n",
    "                    if escala >= 255:\n",
    "                        R = 255\n",
    "                        G = escala - 255\n",
    "                        B = 0\n",
    "                    else:\n",
    "                        R = escala\n",
    "                        G = 0\n",
    "                        B = 0\n",
    "\n",
    "                # Dibuja el contenedor y clase\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (R, G, B), 3)\n",
    "                cv2.putText(img, track_id + ' ' + classNames[cls] , [x1, y1], cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, B), 2)\n",
    "\n",
    "        # Muestra fotograma\n",
    "        cv2.imshow('Vid', img)\n",
    "    \n",
    "    # Detenemos pulsado ESC\n",
    "    if cv2.waitKey(20) == 27:\n",
    "        break\n",
    "  \n",
    "# Libera el objeto de captura\n",
    "vid.release()\n",
    "# Destruye ventanas\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intregración con seguimiento (tracking)\n",
    "!!!!!!!!!Nota: he tenido que bajar a la versión de python 3.9.5 e instalar lap con pip install lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga del modelo\n",
    "model = YOLO('yolo11n.pt') #Contenedores\n",
    "#model = YOLO('yolov11n-seg.pt') #Máscaras\n",
    "#model = YOLO('yolo11n-pose.pt')  #Pose\n",
    "\n",
    "#Para un vídeo \n",
    "filename = \"TGC23_PdH_C0056cut.mp4\"\n",
    "results = model.track(source=filename, show=True)  # BoT-SORT tracker (por defecto)\n",
    "#results = model.track(source=filename, show=True, tracker=\"bytetrack.yaml\")  # ByteTrack tracker\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconocimiento de caracteres tras instalar pytesseract y tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tesseract\n",
    "import cv2\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "\n",
    "# Previamente debes descargar los ejecutables\n",
    "# Si la ruta de Tesseract no está en el PATH, ruta al ejecutable\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:/Program Files/Tesseract-OCR/tesseract'\n",
    "\n",
    "# Lenguajes disponibles\n",
    "print(pytesseract.get_languages(config=''))\n",
    "\n",
    "#Cargo imagen y ocnvierto a RGB\n",
    "img = cv2.imread('ocr_test.tif') \n",
    "\n",
    "if img is not None:\n",
    "    #Convierte a RGB antes de procesar\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    #Texto localizado\n",
    "    print(pytesseract.image_to_string(img))\n",
    "\n",
    "    #Texto y localización en imagen de cada palabra\n",
    "    d = pytesseract.image_to_data(img_rgb, output_type=Output.DICT)\n",
    "\n",
    "    n_boxes = len(d['text'])\n",
    "    for i in range(n_boxes):\n",
    "        #Nivel de confianza\n",
    "        if int(d['conf'][i]) > 60:\n",
    "            text = d['text'][i]\n",
    "            conf = d['conf'][i]\n",
    "            (x, y, w, h) = (d['left'][i], d['top'][i], d['width'][i], d['height'][i])\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "            print(f'Texto: {text} ({conf:.2f}%)\\nContenedor: {x,y,x+w,y+h}')\n",
    "\n",
    "    cv2.imshow('img', img_rgb)\n",
    "    cv2.waitKey(-1)\n",
    "\n",
    "   \n",
    "\n",
    "else:\n",
    "    print('Error de imagen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconocimiento de caracteres tras instalar easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "\n",
    "#Carga del modelo de lengua\n",
    "reader = easyocr.Reader(['es']) \n",
    "\n",
    "#Reconocimiento de una imagen\n",
    "res = reader.readtext('ocr_test.tif')\n",
    "\n",
    "for (bbox, text, prob) in res:\n",
    "    # Coordenadas en orden \n",
    "    (top_left, top_right, bottom_right, bottom_left) = bbox\n",
    "    print(f'\\nTexto: {text}\\nProbabilidad: {prob:.2f}\\nContenedor: {tuple(map(int, top_left)),tuple(map(int, bottom_right))}')\n",
    "\n",
    "\n",
    "#Con restricción de caracteres reconocibles\n",
    "#result = reader.readtext('toy.tif', allowlist ='0123456789')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
