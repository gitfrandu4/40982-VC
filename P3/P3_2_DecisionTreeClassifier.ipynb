{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Initialize lists to hold data and labels\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# List of image files and corresponding labels\n",
    "image_files = ['FRA.png', 'PEL.png', 'TAR.png']\n",
    "image_labels = ['Fragment', 'Pellet', 'Tar']\n",
    "\n",
    "# Loop over the images\n",
    "for idx, file in enumerate(image_files):\n",
    "    # Load the image\n",
    "    image = cv2.imread(file)\n",
    "    if image is None:\n",
    "        print(f\"Error loading image {file}\")\n",
    "        continue\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian Blur to reduce noise\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Apply adaptive thresholding\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY_INV, 11, 2\n",
    "    )\n",
    "\n",
    "    # Remove small noise with morphological operations\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    opening = cv2.morphologyEx(\n",
    "        thresh, cv2.MORPH_OPEN, kernel, iterations=2\n",
    "    )\n",
    "\n",
    "    # Find contours\n",
    "    contours, hierarchy = cv2.findContours(\n",
    "        opening, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "\n",
    "    # Loop over the contours\n",
    "    for cnt in contours:\n",
    "        # Filter by area (ignore very small particles)\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > 20:  # Adjust threshold as needed\n",
    "            # Compute perimeter\n",
    "            perimeter = cv2.arcLength(cnt, True)\n",
    "\n",
    "            # Compactness\n",
    "            compactness = (perimeter ** 2) / area if area != 0 else 0\n",
    "\n",
    "            # Bounding rectangle\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            aspect_ratio = float(w) / h if h != 0 else 0\n",
    "            area_rect_ratio = area / (w * h) if (w * h) != 0 else 0\n",
    "\n",
    "            # Fit ellipse if possible\n",
    "            if len(cnt) >= 5:\n",
    "                ellipse = cv2.fitEllipse(cnt)\n",
    "                (center, axes, orientation) = ellipse\n",
    "                major_axis = max(axes)\n",
    "                minor_axis = min(axes)\n",
    "                ellipse_axis_ratio = minor_axis / major_axis if major_axis != 0 else 0\n",
    "            else:\n",
    "                ellipse_axis_ratio = 0\n",
    "\n",
    "            # Centroid and distances\n",
    "            M = cv2.moments(cnt)\n",
    "            if M['m00'] != 0:\n",
    "                cx = int(M['m10'] / M['m00'])\n",
    "                cy = int(M['m01'] / M['m00'])\n",
    "                # Calculate distances from centroid to contour points\n",
    "                distances = [cv2.pointPolygonTest(cnt, (cx, cy), True) for point in cnt]\n",
    "                max_dist = np.max(distances)\n",
    "                min_dist = np.min(distances)\n",
    "                dist_ratio = min_dist / max_dist if max_dist != 0 else 0\n",
    "            else:\n",
    "                dist_ratio = 0\n",
    "\n",
    "            # Collect features\n",
    "            features = [\n",
    "                area, perimeter, compactness,\n",
    "                area_rect_ratio, aspect_ratio,\n",
    "                ellipse_axis_ratio, dist_ratio\n",
    "            ]\n",
    "            data.append(features)\n",
    "            labels.append(image_labels[idx])\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data, columns=[\n",
    "    'Area', 'Perimeter', 'Compactness',\n",
    "    'Area_Rect_Ratio', 'Aspect_Ratio',\n",
    "    'Ellipse_Axis_Ratio', 'Dist_Ratio'\n",
    "])\n",
    "df['Label'] = labels\n",
    "\n",
    "# Prepare data for training\n",
    "X = df.drop('Label', axis=1)\n",
    "y = df['Label']\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Train a Decision Tree classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=clf.classes_)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm, annot=True, fmt='d',\n",
    "    xticklabels=clf.classes_, yticklabels=clf.classes_,\n",
    "    cmap='Blues'\n",
    ")\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
