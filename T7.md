# Tema 7 - Movimiento en Visión por Computador

<img src="img/cover-t7.png" alt="Cover" width="1000"/>

<div class="page"/>

## Índice

- [Tema 7 - Movimiento en Visión por Computador](#tema-7---movimiento-en-visión-por-computador)
  - [Índice](#índice)
  - [1. Introducción](#1-introducción)
    - [1.1 ¿Qué es el movimiento en visión por computador?](#11-qué-es-el-movimiento-en-visión-por-computador)
    - [1.2 Estimación del movimiento](#12-estimación-del-movimiento)
    - [1.3 Alineamiento de imágenes](#13-alineamiento-de-imágenes)
      - [1.3.1 Homografías](#131-homografías)
      - [RANSAC](#ransac)
      - [1.3.2 Estabilización de cámara](#132-estabilización-de-cámara)
    - [1.4 Movimiento como pista perceptiva](#14-movimiento-como-pista-perceptiva)
  - [2. Alineamiento Traslacional](#2-alineamiento-traslacional)
    - [Usos principales:](#usos-principales)
    - [2.1 Definición y métodos](#21-definición-y-métodos)
      - [Definición](#definición)
      - [Métodos básicos:](#métodos-básicos)
      - [Aplicaciones:](#aplicaciones)
    - [2.2 Técnicas para minimizar errores](#22-técnicas-para-minimizar-errores)
      - [2.2.1 SSD (Sum of Squared Differences)](#221-ssd-sum-of-squared-differences)
      - [2.2.2 Correlación cruzada normalizada](#222-correlación-cruzada-normalizada)
    - [2.3 Estimación jerárquica y refinamiento](#23-estimación-jerárquica-y-refinamiento)
      - [Proceso:](#proceso)
      - [Refinamiento:](#refinamiento)
    - [Resumen:](#resumen)
  - [3. Flujo Óptico](#3-flujo-óptico)
    - [3.1 Concepto y usos](#31-concepto-y-usos)
      - [Usos principales:](#usos-principales-1)
    - [3.2 Métodos principales](#32-métodos-principales)
    - [Problema de apertura](#problema-de-apertura)
      - [3.2.1 Lucas-Kanade](#321-lucas-kanade)
        - [Pasos principales:](#pasos-principales)
        - [Ventajas:](#ventajas)
        - [Limitaciones:](#limitaciones)
- [Cargar video](#cargar-video)
- [Puntos de interés iniciales](#puntos-de-interés-iniciales)
- [Parámetros del método Lucas-Kanade](#parámetros-del-método-lucas-kanade)
      - [3.2.2 Problemas del flujo óptico](#322-problemas-del-flujo-óptico)
        - [Problema de apertura:](#problema-de-apertura-1)
        - [Iluminación:](#iluminación)
        - [Movimientos grandes:](#movimientos-grandes)
    - [3.3 Segmentación basada en flujo óptico](#33-segmentación-basada-en-flujo-óptico)
      - [Proceso:](#proceso-1)
    - [3.4 Aprendizaje en flujo óptico (FlowNet, RAFT)](#34-aprendizaje-en-flujo-óptico-flownet-raft)
      - [3.4.1 FlowNet](#341-flownet)
      - [3.4.2 RAFT (Recurrent All-Pairs Field Transforms)](#342-raft-recurrent-all-pairs-field-transforms)
      - [Aplicaciones modernas:](#aplicaciones-modernas)
    - [Resumen:](#resumen-1)
  - [4. Seguimiento](#4-seguimiento)
    - [4.1 Introducción al seguimiento](#41-introducción-al-seguimiento)
      - [4.1.1 Detección basada en seguimiento](#411-detección-basada-en-seguimiento)
      - [4.1.2 Tipos de seguimiento (SOT, MOT)](#412-tipos-de-seguimiento-sot-mot)
    - [4.2 Métodos de seguimiento](#42-métodos-de-seguimiento)
      - [4.2.1 Puntos de interés](#421-puntos-de-interés)
      - [4.2.2 Sustracción de fondo](#422-sustracción-de-fondo)
      - [4.2.3 Modelos avanzados (DeepSORT, ByteTrack)](#423-modelos-avanzados-deepsort-bytetrack)
  - [5. Filtro de Kalman](#5-filtro-de-kalman)
    - [5.1 Principios básicos](#51-principios-básicos)
      - [Conceptos clave:](#conceptos-clave)
      - [Supuestos:](#supuestos)
    - [5.2 Uso en estimación dinámica](#52-uso-en-estimación-dinámica)
      - [5.2.1 Sistemas estáticos](#521-sistemas-estáticos)
      - [5.2.2 Sistemas dinámicos](#522-sistemas-dinámicos)
    - [5.3 Aplicaciones prácticas](#53-aplicaciones-prácticas)
      - [Ejemplos en visión por computador:](#ejemplos-en-visión-por-computador)
    - [Resumen](#resumen-2)

<div class="page"/>

## 1. Introducción

Contenidos:

* Introducción
* Traslacional
* Flujo óptico
* Seguimiento
* Filtro de Kalman

### 1.1 ¿Qué es el movimiento en visión por computador?

El movimiento en visión por computador se refiere al cambio de posición de los objetos en una secuencia de imágenes o video. Es clave para tareas como:
- Seguimiento de objetos.
- Reconocimiento de actividades.
- Estabilización de cámara.

### 1.2 Estimación del movimiento

Consiste en calcular el desplazamiento de píxeles, objetos o patrones entre dos imágenes consecutivas.

<img src="img/motion-estimation.png" alt="Motion Estimation" width="600"/>

### 1.3 Alineamiento de imágenes

<img src="img/image-alignment.png" alt="Image Alignment" width="600"/>

#### 1.3.1 Homografías

<img src="img/homography.png" alt="Homography" width="600"/>

- Utilizadas para transformar imágenes y empalmarlas (**_image stitching_**).
- Ejemplo: Panoramas de fotografías.

<img src="img/perspective-warp.png" alt="Perspective Warp" width="600"/>

#### RANSAC

RANSAC (_RANdom SAmple Consensus_) es un algoritmo robusto para estimar parámetros de modelos matemáticos. Se utiliza para eliminar valores atípicos (outliers) en la estimación de homografías.

Funcionamiento de RANSAC:

* Escoger par(es) de puntos aleatorios.
* Contar _inliers_ (puntos que cumplen con el modelo).
* Repetir hasta encontrar el mejor modelo.

Traslación con mator número de _inliers_. 
Repeticiones según número de muestras y probabilidad de _inliers_.

<img src="img/ransac.png" alt="RANSAC" width="600"/>

#### 1.3.2 Estabilización de cámara

- Suaviza movimientos de video mediante alineamiento de fotogramas consecutivos.

### 1.4 Movimiento como pista perceptiva

* A veces única pista disponible. 

<div class="page"/>

## 2. Alineamiento Traslacional

El alineamiento traslacional es el método más simple para alinear dos imágenes, considerando solo desplazamientos horizontales y verticales. Su objetivo principal es encontrar la traslación que minimice la diferencia entre las dos imágenes.

<img src="img/translation-alignment.png" alt="Translation Alignment" width="600"/>

### Usos principales:
1. **Seguimiento de objetos**: Detectar y seguir el movimiento de un objeto en secuencias de imágenes.
2. **Corrección de movimiento de cámara**: Compensar movimientos indeseados en videos.

---

### 2.1 Definición y métodos
#### Definición
El alineamiento traslacional se basa en mover una imagen sobre otra para que coincidan de la mejor manera posible. Esto implica calcular un desplazamiento \( (u, v) \) que minimice la diferencia entre las intensidades de los píxeles correspondientes.

#### Métodos básicos:
1. **Búsqueda exhaustiva**: Probar todos los posibles desplazamientos dentro de un rango definido.
2. **Optimización jerárquica**: Utilizar diferentes niveles de resolución para aproximar la solución más rápidamente.

#### Aplicaciones:
- Estabilización de cámara en videos.
- Creación de panoramas al empalmar imágenes.
- Seguimiento básico de objetos en imágenes consecutivas.

**Ejemplo práctico con OpenCV (búsqueda exhaustiva)**:

```python
import cv2
import numpy as np

# Cargar imágenes
img1 = cv2.imread("img1.jpg", 0)  # Imagen de referencia
img2 = cv2.imread("img2.jpg", 0)  # Imagen a alinear

# Búsqueda exhaustiva en un rango de desplazamiento
best_score = float('inf')
best_u, best_v = 0, 0

for u in range(-10, 10):  # Rango horizontal
    for v in range(-10, 10):  # Rango vertical
        shifted = np.roll(img2, (u, v), axis=(0, 1))
        score = np.sum((img1 - shifted) ** 2)  # SSD
        if score < best_score:
            best_score = score
            best_u, best_v = u, v

print(f"Mejor desplazamiento: ({best_u}, {best_v})")
```

---

### 2.2 Técnicas para minimizar errores
#### 2.2.1 SSD (Sum of Squared Differences)
El **SSD** mide la **diferencia entre dos imágenes sumando los cuadrados de las diferencias de intensidades de píxeles**. Es uno de los métodos más comunes para comparar imágenes.

**Ventajas**:
- Sencillo de implementar.
- Bueno para imágenes con iluminación constante.

**Fórmula**:
```
SSD = \sum_{i,j} \left[ I_1(i,j) - I_2(i+u, j+v) \right]^2
```

Donde \( I_1 \) e \( I_2 \) son las intensidades de las imágenes y \( (u, v) \) es el desplazamiento.

**Limitaciones**:
- Sensible a cambios de iluminación.
- No maneja bien las partes fuera de los límites de las imágenes.

#### 2.2.2 Correlación cruzada normalizada
La correlación cruzada evalúa la similitud entre dos regiones, siendo más robusta frente a cambios de brillo o contraste. Su versión normalizada la escala en el rango [-1, 1].

**Fórmula**:
```
NCC = \frac{\sum_{i,j} \left[ (I_1(i,j) - \mu_1) \cdot (I_2(i+u, j+v) - \mu_2) \right]}
{\sqrt{\sum_{i,j} (I_1(i,j) - \mu_1)^2 \cdot \sum_{i,j} (I_2(i+u, j+v) - \mu_2)^2}}
```

Donde \( \mu_1 \) y \( \mu_2 \) son las medias de las intensidades de las imágenes.

**Ventajas**:
- Insensible a cambios globales de brillo.
- Adecuada para aplicaciones con iluminación variable.

**Ejemplo práctico con OpenCV (correlación cruzada)**:

```python
import cv2
import numpy as np

# Cargar imágenes
img1 = cv2.imread("img1.jpg", 0)
img2 = cv2.imread("img2.jpg", 0)

# Calcular correlación cruzada
result = cv2.matchTemplate(img2, img1, method=cv2.TM_CCOEFF_NORMED)
_, max_val, _, max_loc = cv2.minMaxLoc(result)

print(f"Mejor correlación: {max_val} en posición {max_loc}")
```

---

### 2.3 Estimación jerárquica y refinamiento
En problemas de alineamiento de imágenes, una aproximación jerárquica mejora la eficiencia al trabajar con diferentes resoluciones (pirámides de imágenes).

<img src="img/hierarchical-alignment.png" alt="Hierarchical Alignment" width="600"/>

#### Proceso:
1. **Reducción de resolución**: Crear versiones reducidas de las imágenes.
2. **Alineamiento en baja resolución**: Calcular el desplazamiento inicial en la resolución más baja.
3. **Refinamiento progresivo**: Usar la estimación obtenida como punto de partida en resoluciones más altas.

**Ventajas**:
- Más rápido que la búsqueda exhaustiva a alta resolución.
- Proporciona una aproximación inicial precisa.

#### Refinamiento:
Después de alinear las imágenes hasta el píxel más cercano, se puede afinar el desplazamiento buscando en subpíxeles mediante interpolación.

**Ejemplo práctico con OpenCV (jerárquico)**:

```python
import cv2
import numpy as np

# Cargar imágenes
img1 = cv2.imread("img1.jpg", 0)
img2 = cv2.imread("img2.jpg", 0)

# Calcular alineamiento usando ECC (Enhanced Correlation Coefficient)
warp_matrix = np.eye(2, 3, dtype=np.float32)
criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 50, 1e-6)
_, warp_matrix = cv2.findTransformECC(img1, img2, warp_matrix, cv2.MOTION_TRANSLATION, criteria)

print("Matriz de transformación jerárquica:\n", warp_matrix)
```

---

### Resumen:
1. **Alineamiento traslacional** es el método más simple para alinear imágenes desplazándolas horizontal o verticalmente.
2. **Técnicas comunes**:
   - SSD: Suma de diferencias cuadradas.
   - NCC: Correlación cruzada normalizada.
3. **Estimación jerárquica** acelera el alineamiento inicial y mejora la precisión mediante refinamiento.

Con este conocimiento, puedes abordar preguntas relacionadas con el alineamiento traslacional y su implementación práctica en OpenCV.

<div class="page"/>

## 3. Flujo Óptico

### 3.1 Concepto y usos

El flujo óptico describe el movimiento aparente de los píxeles entre dos imágenes consecutivas en un video. Este movimiento puede deberse al cambio de posición de los objetos, al movimiento de la cámara o incluso a cambios en la iluminación.

<img src="img/optical-flow.png" alt="Optical Flow" width="600"/>
<img src="img/optical-flow-2.png" alt="Optical Flow 2" width="600"/>

Aproximación del movimiento real (en muchos casos). Producido por:

* movimiento de cámara
* del objeto
* o iluminación (no movimiento real)

#### Usos principales:
1. **Seguimiento de objetos**: Determinar la trayectoria de un objeto en una secuencia de imágenes.
2. **Reconocimiento de actividades**: Analizar patrones de movimiento para identificar acciones específicas.
3. **Estructura desde movimiento**: Calcular la geometría 3D de una escena usando la información del movimiento.
4. **Estabilización de cámara**: Suavizar videos eliminando movimientos no deseados.

---

### 3.2 Métodos principales

Existen varios métodos para calcular el flujo óptico. Estos se basan en dos supuestos fundamentales:
1. **Constancia de brillo**: La intensidad de un píxel no cambia entre dos imágenes consecutivas.
2. **Movimiento pequeño**: Los desplazamientos entre imágenes son pequeños.

---

### Problema de apertura

El problema de apertura en visión por computador se refiere a la ambigüedad en la estimación del flujo óptico cuando el movimiento no puede determinarse de manera unívoca. Esto ocurre típicamente en regiones donde falta información direccional suficiente, como en bordes rectos o superficies planas.

<img src="img/aperture-problem.png" alt="Aperture Problem" width="600"/>

**Descripción**:

1. En regiones homogéneas o con texturas uniformes, los cambios de intensidad son mínimos, lo que dificulta determinar el desplazamiento real.

1. En bordes rectos, sólo se puede estimar el movimiento en la dirección perpendicular al borde, mientras que el movimiento paralelo al borde permanece ambiguo.

3. Este problema afecta la calidad del flujo óptico calculado, especialmente en métodos locales como Lucas-Kanade.

Ejemplo:

* Supongamos una línea recta que se mueve horizontalmente. Desde un punto de vista local, no es posible distinguir si la línea se está moviendo horizontalmente o si simplemente no se mueve en absoluto, ya que los gradientes perpendiculares al borde son nulos.

**Ilusión palo del barbero**:

* Un ejemplo clásico del problema de apertura es la ilusión del palo del barbero, donde un cilindro giratorio parece desplazarse en una dirección diferente a la real debido a la falta de información direccional en ciertas regiones.

<img src="img/barber-pole-illusion.png" alt="Barber Pole Ill>

**Soluciones comunes**:

1. Lucas-Kanade con coherencia espacial: Integra información de vecindades para resolver mejor el flujo en regiones ambiguas.

2. Buenas características para rastrear: Usar esquinas o puntos con texturas ricas que no sufran del problema de apertura.

3. Modelos jerárquicos: Calcular el flujo en múltiples resoluciones para reducir ambigüedades.

#### 3.2.1 Lucas-Kanade

Es un método local que asume que el flujo óptico dentro de una pequeña vecindad de un píxel es constante. Este método resuelve un sistema de ecuaciones lineales para estimar el desplazamiento \( (u, v) \) de cada píxel.

A tener en cuenta: 

* Una ecuación por píxel, con dos incógnitas (u, v).
* Coherencia espacial: idéntico desplazamiento (u, v) en vecindad.
* Más ecuaciones integrando vecindad (5x5 -> 25 ecuaciones).
* Evita problema de apertura usando esquinas.
* Para _n_ vecinos, resolución de mínimos cuadrados

<img src="img/lucas-kanade.png" alt="Lucas-Kanade" width="600"/>

<img src="img/lucas-kanade-2.png" alt="Lucas-Kanade 2" width="600"/>

##### Pasos principales:
1. Calcular los gradientes espaciales (\( I_x \), \( I_y \)) y temporal (\( I_t \)).
2. Resolver las ecuaciones de mínimos cuadrados:
   $$
   \begin{bmatrix}
   u \\
   v
   \end{bmatrix}
   = \left( \sum_{i,j}
   \begin{bmatrix}
   I_x^2 & I_x I_y \\
   I_x I_y & I_y^2
   \end{bmatrix} \right)^{-1}
   \begin{bmatrix}
   -\sum I_x I_t \\
   -\sum I_y I_t
   \end{bmatrix}
   $$

##### Ventajas:
- Rápido y eficiente en vecindades pequeñas.
- Adecuado para movimientos pequeños.

##### Limitaciones:
- No funciona bien con movimientos grandes/amplios.
- Sensible al problema de apertura (falta de información en ciertas regiones).

**Ejemplo práctico con OpenCV**:
$$$
python
import cv2
import numpy as np

# Cargar video
cap = cv2.VideoCapture("video.mp4")
ret, old_frame = cap.read()
old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)

# Puntos de interés iniciales
p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)

# Parámetros del método Lucas-Kanade
lk_params = dict(winSize=(15, 15), maxLevel=2, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break
    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    # Calcular flujo óptico
    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)

    # Dibujar puntos
    for i, (new, old) in enumerate(zip(p1[st == 1], p0[st == 1])):
        x, y = new.ravel()
        cv2.circle(frame, (int(x), int(y)), 5, (0, 255, 0), -1)

    cv2.imshow("Lucas-Kanade Optical Flow", frame)

    if cv2.waitKey(30) & 0xFF == ord('q'):
        break

    old_gray = frame_gray.copy()
    p0 = p1[st == 1].reshape(-1, 1, 2)

cap.release()
cv2.destroyAllWindows()
$$$

---

#### 3.2.2 Problemas del flujo óptico

##### Problema de apertura:
- En regiones con poca textura (e.g., superficies planas), el desplazamiento no puede determinarse de forma única. Esto se debe a la falta de información direccional suficiente.

##### Iluminación:
- Cambios de iluminación entre fotogramas pueden afectar la precisión de los cálculos.

##### Movimientos grandes:
- Métodos locales como Lucas-Kanade no son efectivos si los objetos tienen desplazamientos grandes entre fotogramas.

---

### 3.3 Segmentación basada en flujo óptico

La segmentación basada en flujo óptico consiste en dividir la imagen en regiones según el movimiento. Esto es útil para identificar objetos que se mueven de manera diferente a su entorno.

#### Proceso:
1. Calcular el flujo óptico para todos los píxeles.
2. Agrupar píxeles con movimientos similares en capas o segmentos.

**Ejemplo de uso**:
- En videovigilancia, separar personas caminando de un fondo estático.

---

### 3.4 Aprendizaje en flujo óptico (FlowNet, RAFT)

Los enfoques modernos utilizan redes neuronales para calcular el flujo óptico de manera precisa y rápida.

#### 3.4.1 FlowNet
- Primera arquitectura basada en redes neuronales para flujo óptico.
- Entrenada con datos sintéticos y reales.
- Ventajas: Capaz de manejar movimientos grandes y escenas complejas.

<img src="img/flownet.png" alt="FlowNet" width="600"/>

#### 3.4.2 RAFT (Recurrent All-Pairs Field Transforms)
- Una de las técnicas más avanzadas en flujo óptico.
- Modelo basado en calcular todas las posibles correspondencias entre píxeles.
- Ventajas: Alta precisión y robustez en escenarios complicados.

<img src="img/raft.png" alt="RAFT" width="600"/>

#### Aplicaciones modernas:
1. **Reconocimiento de acciones**: Analizar el movimiento de personas en un video.
2. **Interpolación de cuadros**: Crear fotogramas intermedios para videos en cámara lenta.
3. **Reconstrucción 3D**: Usar el flujo óptico para estimar la profundidad de la escena.
4. **Flujo óptico como entrada para reconocimiento de acciiones**. CNNs 

<img src="img/optical-flow-applications.png" alt="Optical Flow Applications" width="600"/>

**Ejemplo práctico**:
Aunque OpenCV no incluye directamente RAFT o FlowNet, se pueden usar implementaciones externas en PyTorch para proyectos avanzados.

---

### Resumen:
1. El flujo óptico es una técnica esencial para capturar y analizar el movimiento en visión por computador.
2. Métodos clásicos como Lucas-Kanade son rápidos pero tienen limitaciones.
3. Enfoques basados en aprendizaje profundo como FlowNet y RAFT ofrecen resultados más precisos en escenarios complejos.

Estudiar estos conceptos y practicar con OpenCV te permitirá enfrentar cualquier pregunta relacionada con flujo óptico en un examen o proyecto.

<div class="page"/>

## 4. Seguimiento
### 4.1 Introducción al seguimiento
#### 4.1.1 Detección basada en seguimiento
#### 4.1.2 Tipos de seguimiento (SOT, MOT)
### 4.2 Métodos de seguimiento
#### 4.2.1 Puntos de interés
#### 4.2.2 Sustracción de fondo
#### 4.2.3 Modelos avanzados (DeepSORT, ByteTrack)

<div class="page"/>

## 5. Filtro de Kalman

### 5.1 Principios básicos
El filtro de Kalman es un algoritmo recursivo que estima el estado futuro de un sistema dinámico a partir de mediciones ruidosas y un modelo del sistema. Este se utiliza ampliamente en visión por computador y otras áreas debido a su capacidad para manejar incertidumbre en mediciones.

<img src="img/kalman-filter.png" alt="Kalman Filter" width="600"/>

* Durante el seguimiento de objetos, el filtro de Kalman ayuda a predecir la posición futura de un objeto y corregir errores en mediciones.
* Se basa en dos pasos: predicción y corrección del estado del sistema.

Dadas estimación y medición, estima el estado futiro del objetivo. 
En seguimiento, medición proporcionada por la detección.

<img src="img/kalman-steps.png" alt="Kalman Steps" width="600"/>

#### Conceptos clave:
- **Estado del sistema**: Representación de variables relevantes (e.g., posición, velocidad).
- **Predicción**: Proyección del estado futuro del sistema basada en el modelo dinámico.
- **Corrección**: Ajuste del estado predicho utilizando nuevas mediciones.
- **Ganancia de Kalman**: Determina cuánto se debe confiar en las mediciones frente al modelo predicho.

#### Supuestos:
1. El sistema tiene una dinámica lineal.
2. El ruido es blanco, aditivo y gaussiano.
3. Las mediciones pueden estar sujetas a errores.

**Ecuaciones principales**:
- **Predicción del estado**:
```
x_k' = A \cdot x_{k-1} + B \cdot u
```
- **Corrección del estado**:
```
x_k = x_k' + K \cdot (z_k - H \cdot x_k')
```
Donde \( x_k \) es el estado, \( z_k \) es la medición y \( K \) es la ganancia de Kalman.

---

### 5.2 Uso en estimación dinámica
El filtro de Kalman puede aplicarse en diferentes escenarios según la naturaleza del sistema que se quiera modelar.

#### 5.2.1 Sistemas estáticos
En sistemas donde no hay cambios significativos en el estado del sistema, el filtro se utiliza para reducir el impacto del ruido de medición.

**Ejemplo práctico**:
- Un radar detectando un avión en tierra. Aunque el avión no se mueve, las mediciones tienen errores debido a factores como ruido de sensores.

**Modelo estático**:
- **Estado constante**: \( x_k = x_{k-1} \)
- **Actualización basada en mediciones**:
```
x_k = x_{k-1} + K \cdot (z_k - x_{k-1})
```

---

#### 5.2.2 Sistemas dinámicos
En sistemas donde el estado cambia con el tiempo, como un coche en movimiento, el filtro utiliza un modelo dinámico que incorpora la velocidad y la aceleración.

**Ejemplo práctico**:
- Seguimiento de un coche con velocidad constante.
- Modelo dinámico: \( x_k = x_{k-1} + v \cdot t \), donde \( v \) es la velocidad.

**Predicción del estado**:
```
x_k' = x_{k-1} + v \cdot t
```

**Corrección del estado con mediciones**:
```
x_k = x_k' + K \cdot (z_k - x_k')
```

**Ganancia de Kalman ajusta la confianza**:
- Ganancia alta (\( K \approx 1 \)): Se confía más en la medición.
- Ganancia baja (\( K \approx 0 \)): Se confía más en la predicción previa.

**Ejemplo con OpenCV**:

```python
import cv2
import numpy as np

# Configurar filtro de Kalman
kf = cv2.KalmanFilter(4, 2)  # 4 estados, 2 mediciones
kf.transitionMatrix = np.array([[1, 0, 1, 0],
                                [0, 1, 0, 1],
                                [0, 0, 1, 0],
                                [0, 0, 0, 1]], np.float32)
kf.measurementMatrix = np.eye(2, 4, dtype=np.float32)
kf.processNoiseCov = np.eye(4, dtype=np.float32) * 0.03

# Predicción y corrección
prediction = kf.predict()
measurement = np.array([x, y], dtype=np.float32)
corrected = kf.correct(measurement)

print("Predicción:", prediction)
print("Corrección:", corrected)
```

---

### 5.3 Aplicaciones prácticas
El filtro de Kalman es ampliamente utilizado en tareas donde es necesario estimar el estado de un sistema dinámico con alta precisión.

#### Ejemplos en visión por computador:
1. **Seguimiento de objetos**:
   - Rastrear personas o vehículos en videos.
   - Predecir su posición en el siguiente cuadro.

2. **Reconocimiento de gestos**:
   - Estimar el movimiento de manos, cabezas o labios.
   - Útil en interfaces hombre-máquina.

3. **Videovigilancia**:
   - Monitorizar personas u objetos en entornos dinámicos.

4. **Economía y predicción de datos**:
   - Filtrar ruido en datos financieros y predecir tendencias futuras.

5. **Navegación**:
   - Seguimiento de drones, vehículos autónomos y satélites.

**Ejemplo de aplicación**:
- Un dron en vuelo utiliza un filtro de Kalman para estimar su posición y velocidad basándose en mediciones ruidosas del GPS y acelerómetros. Esto permite un control más preciso del vuelo.

### Resumen

* Algoritmo que estima el estado del sistema
* Estima variables ocultas a partir de otras observables
* Maximiza probabilidad a posteriori
* Asume
  * Dinámica lineal
  * Ruido blanco, aditivo y gaussiano de las mediciones

<img src="img/kalman-example.png" alt="Kalman Summary" width="600"/>
